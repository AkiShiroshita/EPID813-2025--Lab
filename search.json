[
  {
    "objectID": "slide-embed.html",
    "href": "slide-embed.html",
    "title": "Embed Slides",
    "section": "",
    "text": "On this page, we show how we can embed a RevealJS Presentation inside of a Quarto Website."
  },
  {
    "objectID": "slide-embed.html#presentation",
    "href": "slide-embed.html#presentation",
    "title": "Embed Slides",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nFor quarto-webr to work within RevealJS, you must use a pre-release version of Quarto that is 1.4.502 or greater that contains an updated copy of pandoc. For more details, please see Issue #14."
  },
  {
    "objectID": "slide-embed.html#embed-code",
    "href": "slide-embed.html#embed-code",
    "title": "Embed Slides",
    "section": "Embed Code",
    "text": "Embed Code\nPlace the following code inside of the Quarto Document:\n&lt;style&gt;\n.slide-deck {\n    border: 3px solid #dee2e6;\n    width: 100%;\n    height: 475px;\n}\n&lt;/style&gt;\n\n&lt;div&gt;\n```{=html}\n&lt;iframe class=\"slide-deck\" src=\"path/to/presentation/\"&gt;&lt;/iframe&gt;\n```\n&lt;/div&gt;"
  },
  {
    "objectID": "Midterm_review.html",
    "href": "Midterm_review.html",
    "title": "Midterm review",
    "section": "",
    "text": "Bias\n\nSuppose the true population:\n\n\n\n\nCases\nControls\nTotal\n\n\n\n\nExposed\n30\n70\n100\n\n\nUnexposed\n20\n80\n100\n\n\n\nObserved population:\n\n\n\n\nCases\nControls\nTotal\n\n\n\n\nExposed\n30\n20\n50\n\n\nUnexposed\n20\n80\n100\n\n\n\n\n\n\n\n\n\nQ1: What is this bias called? If the true population is unknown but the selection probabilities are known, how can this bias be corrected?\n\n\n\n\n\nA: selection bias.\n\n\n\nSelection probabilities\nCases\nControls\n\n\n\n\n\nExposed\n\\(S_{A,1}\\)\n\\(S_{B,1}\\)\n\n\n\nUnexposed\n\\(S_{A,0}\\)\n\\(S_{B,0}\\)\n\n\n\n\nTRUE \\(OR = \\hat{OR}/\\frac{S_{A,1}S_{B,0}}{S_{A,0}S_{B,1}}\\)\nwhere selection odds ratio = \\(\\frac{S_{A,1}S_{B,0}}{S_{A,0}S_{B,1}}\\)\nTo cause selection bias, selection should depend jointly on the exposure and outcome.\nThe following scenarios do not cause bias:\n\nIf selection depends only on exposure\nIf selection depends only on outcome\nIf selection depends proportionally on both (independently) \\(\\rightarrow P(selected|exposure,outcome)=f(exposure) \\times g(outcome)\\)\n\n\n\n\nSuppose the true population:\n\n\n\nTrue Smoking\nLung Cancer\nNo Lung Cancer\nTotal\n\n\n\n\nSmoker\n40\n60\n100\n\n\nNon-Smoker\n10\n90\n100\n\n\n\n\n\n\n\n\n\nQ2: If 20% of smokers are misclassified as non-smokers, what is the observed odds ratio between smoking and lung cancer? What is this bias called?\n\n\n\n\n\n\n\n\nObserved Smoking\nLung Cancer\nNo Lung Cancer\nTotal\n\n\n\n\nSmoker\n40-40*0.2=32\n60-60*0.2=48\n80\n\n\nNon-Smoker\n10+40*0.2=18\n90+60*0.2=102\n120\n\n\n\nA: The observed odds ratio is (32*102)/(48*18)=3.78. This bias is called non-differential misclassification of a binary exposure.\n\n\n\n\n\n\n\n\n\nQ3: Non-differential misclassification always biased the estimate toward the null. Is that correct?\n\n\n\n\n\nA: FALSE\nExceptions:\n\nIf the exposure has more than two categories\nIf the exposure is continuous\nOutcome misclassification\n\netc. (Please see the Journal Club)\n\n\n\n\n\n\n\n\n\nQ4: In a prospective study comparing myocardial infarction mortality between office workers and longshoremen, individuals who self-select into longshoremen are generally fitter, which leads to lower myocardial infarction rates. What type of bias does this introduce?\n\n\n\n\n\nA: confounding bias from a traditional epidemiological view (not selection bias)\nThe difference is that, in confounding, individuals self-select into exposure groups, whereas in selection bias, the researcher’s process of selecting participants into the study creates the bias.\nTraditional view is cohort studies don’t have selection bias at entry even if subjects self-select.\nCohort studies/RCTs can have selection bias at end through differential loss to follow-up.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMissing data\n\n\n\n\n\n\n\nQ5: One important difference between single imputation and multiple imputation is that the latter can appropriately account for the uncertainty of the imputed values. Another important difference is that the outcome variable should be included in the multiple imputation model. Is that correct?\n\n\n\n\n\nA: TRUE\nIt is recommended to include the outcome variable in the imputation model, even if the outcome is not missing, because omitting it can bias regression coefficients. However, imputing outcome is a debatable topic.\n\n\n\n\nModel building\n\n\n\n\n\n\n\nQ6: If you develop a prediction model, what model performance metrics would you report?\n\n\n\n\n\nA:\n\nCalibration: Measures how closely the predicted probabilities agree with the observed outcomes (e.g., calibration plot, Hosmer-Lemeshow test).\nDiscrimination: Measures how well the model distinguishes between individuals with and without the outcome (e.g., AUC/ROC, C-statistic)\n\nWe often use optimism-corrected performance metrics through internal validation (e.g., bootstrapping) to account for overfitting.\nYou may report other metrics as well, such as overall performance (e.g., Brier score) and reclassification metrics (e.g., NRI, IDI)\n\n\n\n\nMatching\n\n\n\n\n\n\n\nQ7: Where do you select cases and controls in a case-control study? Are there any caveats regarding their sources?\n\n\n\n\n\nA:\n\nDetermine cases and and identify a source from which to draw their cases.\nIdentify controls from the same source population.The fundamental principle is that controls should be representative of the population from which the cases arose. In other words, they should be selected independently of exposures.\n\nNaturally occurring pairs, such as twins, can violate this principle in matched case-control studies because their inherent relationship introduces correlation beyond what matching accounts for, potentially biasing the results.\n\n\n\n\n\n\n\n\n\nQ8: In an individual (pair) case-control study, if you match on age and sex, you do not need to adjust for them in the conditional logistic regression model, even if they are potential confounders. Is that correct?\n\n\n\n\n\nA: FALSE\nMatching is for efficiency gain, not for controlling for confounders. Therefore, conditional logistic regression models should include all potential confounders, even if they are matching factors. (If we use frequency matching, we may use unconditional logistic regression with adjustment for all potential confounders, including matching factors)\nIn addition, please note that association of age and sex with the outcome as well as interactions between the exposure and these matching factors cannot be estimated in the conditional logistic regression model.\n\n\n\n\n\n\n\n\n\nQ9: When the outcome is rare, what does the odds ratio estimated from the following matched design represent?: 1. case-cohort sampling, 2. risk-set sampling, and 3. survivor sampling\n\n\n\n\n\n\nCase-cohort sampling: Risk ratio\nRisk-set sampling (density-based sampling): Incidence rate ratio\nSurvivor sampling: Odds ratio\n\nThe derivations are shown in the document I shared earlier.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ10: What is the difference between a case-crossover design and a self-controlled case series?\n\n\n\n\n\nA: Both are “case-only” designs that use individuals as their own controls to study the effects of transient exposures on acute events.\nA case-crossover study is outcome-anchored design, while a self-controlled case series is exposure-anchored design.\nIn a case-crossover study, researchers focus on a specific event (e.g., heart attack) and look back at the exposure history immediately before the event (the “case” period). They then compare this to the exposure history during an earlier period (the “control” period) for the same individual.\nA self-controlled case series, on the other hand, looks at the entire observation period for an individual and divides it into “at-risk” periods (times after a specific exposure) and “control” periods (all other time). It then compares the rate of events during the at-risk periods to the rate of events during the control periods.\n\n\n\n\n\n\n\n\n\n\n\n\n\nPropensity score analysis\n\n\n\n\n\n\n\nQ11: Propensity score is the probability of receiving treatment given covariates. Therefore, we should include predictors of treatment in the propensity score model. Is that correct?\n\n\n\n\n\nA: FALSE\nThe propensity score model should include confounders and predictors of the outcome, but not instrumental variables.\n\n\n\nSuppose 30% of the patients received the treatment, and the following table summarizes their potential outcomes.\n\n\n\nGroup\n\\(E(Y^1)\\)\n\\(E(Y^0)\\)\n\n\n\n\nTreatment\n100\n60\n\n\nNo treatment\n80\n50\n\n\n\n\n\n\n\n\n\nQ12: Calculate the following treatment effects: ATE, ATT, and ATU.\n\n\n\n\n\nA:\nATT: \\(100-60=40\\)\nATU: \\(80-50=30\\)\nATE: \\(0.3*(100-60)+0.7*(80-50)=12+21=33\\)\n\n\n\nBased on the following tables,\n\\(C=0\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n10\n50\n\n\nNo event\n790\n3150\n\n\nTotal\n800\n3200\n\n\n\n\\(C=1\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n200\n250\n\n\nNo event\n800\n750\n\n\nTotal\n1000\n1000\n\n\n\n\n\n\n\n\n\nQ13: Is C a confounder or effect modifier? Hand-calculate adjusted risk ratio using propensity score matching (1:1 matching) and inverse probability weighting.\n\n\n\n\n\nA: C is a confounder because it is associated with both the treatment and the outcome.\n\nWithin each stratum of C, the treatment effect (RR = 0.8) is the same (if C is the effect modifier, RR is not the same across strata).\nThe crude/overall effect (RR = 1.63) is very different from the stratum-specific effects.\n\nPropensity score calculation\n\\(Pr(Tr=1|C=0)=800/(800+3200)=0.2\\)\n\\(Pr(Tr=1|C=1)=1000/(1000+1000)=0.5\\)\n\nPropensity score matching (1:1 matching)\n\nIt is equivalent to taking a random sample of the unexposed group that is equal in size to the exposed group (the risk of the outcome will remain the same as in the original unexposed group), because each exposed individual is matched to one unexposed individual with a similar propensity score (the matched unexposed group is a subset of the original unexposed group, chosen to resemble the exposed group in terms of covariates)\n\\(C=0\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n10\n800*50/3200=12.5\n\n\nNo event\n790\n800*(3200-50)/3200=787.5\n\n\nTotal\n800\n800\n\n\n\n\\(C=1\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n200\n250\n\n\nNo event\n800\n750\n\n\nTotal\n1000\n1000\n\n\n\n\\(Overall\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n210\n262.5\n\n\nNo event\n1590\n1537.5\n\n\nTotal\n1800\n1800\n\n\n\nRR: 0.8\n\nPropensity score weighting\n\n\\(C=0\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n10*(1/0.2)=50\n50*(1/0.8)=62.5\n\n\nNo event\n790*(1/0.2)=3950\n3150*(1/0.8)=3937.5\n\n\n\nTreatment group weight = \\(1/PS=1/0.2=5\\)\nNon-treatment group weight = \\(1/PS=1/(1-0.2)=1.25\\)\n\\(C=1\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n200*(1/0.5)=400\n250*(1/0.5)=500\n\n\nNo event\n800*(1/0.5)=1600\n750*(1/0.5)=1500\n\n\n\nTreatment group weight = \\(1/PS=1/0.5=2\\)\nNon-treatment group weight = \\(1/PS=1/(1-0.5)=2\\)\n\\(Overall\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n450\n562.5\n\n\nNo event\n5550\n5437.5\n\n\nTotal\n6000\n6000\n\n\n\nRR: 0.8",
    "crumbs": [
      "Home",
      "Content",
      "Midterm review"
    ]
  },
  {
    "objectID": "Lab9.html",
    "href": "Lab9.html",
    "title": "Lab 9",
    "section": "",
    "text": "Lab 9 covers\n\nBias analysis\n\n\nQuantitative bias analysis\n\nSimple bias analysis: Deterministic\n\ne.g., sensitivity and specificity of outcome measurement is 85% (95% CI: 80%-90%) and 90% (95% CI: 85%-95%), respectively. \\(\\rightarrow\\) Use the point estimates alone to calculate a single bias-corrected effect estimate.\n\nProbalistic bias analysis: Probalistic\n\ne.g., sensitivity and specificity of outcome measurement is 85% (95% CI: 80%-90%) and 90% (95% CI: 85%-95%), respectively. \\(\\rightarrow\\) Assume probability distributions (e.g., beta distribution) for sensitivity and specificity and simulate many times to obtain a distribution of bias-corrected effect estimates.\n\n\n\n\n\n\n\n\n\n\nMultidimensional bias analysis: Extend simple bias analysis to simulate various parameters and/or adjust for multiple sources of bias simultaneously.\n\nThe order in which bias adjustments should be made is the reverse of the order in which the biases occurred when the data were generated. In other words, we should adjust for the biases that occurred last before addressing those that occurred earlier. Bias adjustments should proceed in reverse chronological order because our goal is to reconstruct the data as they would have appeared had each bias been absent. Correcting in this order allows each adjustment to build appropriately on the previous one.\nConfounding is ordinarily perceived as a population-level phenomenon, whereas misclassification and selection bias typically arises during data collection or tabulation. The simple bias analysis to address misclassification and selection bias should precede the simple bias analysis to address unmeasured confounding.\n\n\n\n\n\n\n\n\n\nWe will use a case–control study examining the association between antidepressant use and the occurrence of breast cancer. The observed OR was 1.2 [0.9–1.6].\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe observed association between antidepressant use and breast cancer may be confounded by unmeasured factors, such as family history of breast cancer.\nInformation on medication use differed across participants, as some data were obtained from pharmacy records while others were based on self-reported use, leading to potential exposure misclassification.\nCases and controls were enrolled into the study at different rates, introducing the selection bias.\n\nLet’s perform a simple bias analysis to adjust for multiple sources of bias in the reverse order.\n\nCases and controls were enrolled into the study at different rates, introducing the selection bias.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nInformation on medication use differed across participants, as some data were obtained from pharmacy records while others were based on self-reported use, leading to potential exposure misclassification.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe observed association between antidepressant use and breast cancer may be confounded by unmeasured factors, such as family history of breast cancer.\n\nLet’s assume this is no effect measure modification for the simplicity.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nBias-corrected Odds ratio\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nSummary-level data vs. Individual-level data\nWe focused on summary-level data for its simplicity.\nA major limitation of the summary-level bias analysis is that is it difficult to adjust for other measured confounders for which adjustment have been."
  },
  {
    "objectID": "Lab7.html",
    "href": "Lab7.html",
    "title": "Lab 7",
    "section": "",
    "text": "Lab 7 covers\n\nGeneralized Estimating Equations (GEE)\nGeneralized Linear Mixed Models (GLMM)\n\n\nDifferences between GEE and GLMM\n\nModeling correlation: GEE models within-subject correlation using a working correlation matrix, whereas GLMM models it through random effects.\n\nGEE assumes “block independence”\n\n\n\n\n\n\n\n\n\nRandom-intercept model\n\\(Y_{ij}=\\beta_0+\\beta_1 t_{ij} + b_{0i} + \\epsilon_{ij}=(\\beta_0 + b_{0i}) + \\beta_1 t_{ij} + \\epsilon_{ij}\\)\nRandom-slope model (random slope + intercept)\n\\(Y_{ij}=\\beta_0+\\beta_1 t_{ij} + b_{0i} + b_{1i}t_{ij} + \\epsilon_{ij}=(\\beta_0 + b_{0i}) + (\\beta_1 + b_{1i}) t_{ij} + \\epsilon_{ij}\\)\n\n\n\n\n\n\n\n\n\n\nUnlike GEE, which typically handles only one level of clustering, GLMM can model more complex hierarchical structures\n\ne.g., patients nested within hospitals and hospitals nested within regions\n\nAssumptions about missing data: GEE assumes data are missing completely at random (MCAR), while GLMM assumes data are missing at random (MAR)\n\nGLMM can provide valid parameter estimates under MAR, because it uses likelihood-based estimation that borrows information from other observed data. In many projects, some patients are lost to follow-up, but the model can still use the data from patients with complete or partial observations.\nOh the other hand, in GEE, if data are missing in a non-MCAR way, estimates may be biased unless you use methods like weighted GEE or multiple imputation.\n\nInference target: GEE estimates population-averaged (marginal) effects, whereas GLMM estimates subject-specific (conditional) effects.\n\ne.g., Mixed-effects logistic regression model provides odds ratio comparing the odds of death between a typical patient received treatment A and a typical patient of the same covariates received treatment B.\n“typical”: two subjects with the same random effect value.\ne.g., GEE provides an odds ratio comparing the odds of death if everyone received treatment A versus if everyone received treatment B.\nWhen the outcome is continuous and the identity link is used, population-averaged and subject-specific effects are identical.\nHowever, for binary and count outcomes, the two estimands differ.\n\n\nR packages\n\ngee\ngeepack\n\nThese packages use different estimation algorithms.\nIn my opinion, either can be used.\n\nnlme::lme\nlme4::lmer\n\nIn my opinion, lme4::lmer is less flexible, but its output is widely supported by other R packages.\nAlso, lme4::glmer allows fitting mixed-effects logistic regression and other models with alternative link functions.",
    "crumbs": [
      "Home",
      "Content",
      "Lab 7"
    ]
  },
  {
    "objectID": "Lab5.html",
    "href": "Lab5.html",
    "title": "Lab 5",
    "section": "",
    "text": "Lab 5 covers\n\nPropensity score analysis\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nVery simplified workflow\n\n\nEstimate the propensity score\n\n\\(Pr(Tr=1|Covariates)\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nUse the propensity score: weighting, matching, stratification, etc.\n\nInverse probability weighting (ATE)\n\nAmong treated: \\(W = 1/PS\\)\nAmong untreated: \\(W = 1/(1-PS)\\)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nBalance check\n\nLove plot, histogram, etc.\nEnsure that the weighted standardized mean difference for each covariate is less than 0.1 (or, if acceptable, less than 0.25).\n\nUnweighted samples\n\nContinuous variables: \\(d=100*\\frac{\\bar{x}_{treatment}-\\bar{x}_{control}}{\\sqrt{\\frac{S^2_{treatment}+S^2_{control}}{2}}}\\)\nBinary variables: \\(d=100*\\frac{\\hat{p}_{treatment}-\\hat{p}_{control}}{\\sqrt{\\frac{\\hat{p}_{treatment}(1-\\hat{p}_{treatment})+\\hat{p}_{control}(1-\\hat{p}_{control})}{2}}}\\)\n\nWeighted samples\n\n\\(\\bar{x}_{weight}=\\frac{\\sum w_i x_i}{\\sum w_i}\\)\n\\(s^2_{weight}=\\frac{\\sum w_i}{(\\sum w_i)^2-\\sum w_i^2} \\sum w_i (x_i-\\bar{x}_{weight})^2\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nRun the outcome analysis\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe will elaborate on this workflow in Lab 5.\n\n\n\n\n\n\nNote\n\n\n\nConsider uncertainty of propensity score estimation! \\(\\rightarrow\\) Use robust standard error or bootstrap confidence interval",
    "crumbs": [
      "Home",
      "Content",
      "Lab 5"
    ]
  },
  {
    "objectID": "Lab3.html",
    "href": "Lab3.html",
    "title": "Lab 3",
    "section": "",
    "text": "Lab 3 covers\n\nMissing data\n\n\nMissing mechanism\nMissing completely at random (MCAR), Missing at random (MAR), and Missing not at random (MNAR)\nThese are assumptions that cannot be directly verified using the data.\n\nExample writing of your method section\n\n\nMissing data were handled using multiple imputation by chained equations, assuming data were missing at random. The imputation model included the covariates used in the outcome analysis (XXX, YYY, and ZZZ), the treatment variable, the outcome variable, and ABC as an auxiliary variable. XXX regression models were fit to each imputed dataset, and the results from 100 imputations were combined using Rubin’s rules. … As a sensitivity analysis, we performed a complete case analysis.\n\n\n\n\n\n\n\n\n\n\n\n\nMy favoriate workflow\n\nPackage-dependent practice\n\nThe standard mice workflow often uses with() and pool().\n# 1. IMPUTE: Create 10 imputed datasets\nimp_multi &lt;- mice(support, m = 10, printFlag = FALSE, seed = 123)\n\n# It's good practice to save the imputation object\n# write_rds(imp_multi, 'imputed_data.rds')\n\n# 2. ANALYZE: Run the model on each imputed dataset\n# The 'with()' function does this automatically\nanalysis_results &lt;- with(imp_multi,\nglm(death ~ dzclass + age + sex + edu + income + race + diabetes + wblc,\nfamily = binomial))\n\n# 3. POOL: Combine the results using Rubin's Rules\npooled_results &lt;- pool(analysis_results)\n\nMy favorite workflow\n\nHowever, you may encounter situations where existing packages do not support your study design (e.g., performing propensity score analysis with multiple imputation).\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nMultiple imputation\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nStack\n\nConvert your multiply imputed datasets into a single dataframe where each imputed dataset is stacked on top of each other.\n\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nNest\n\n\ngroup_by(.imp) -&gt; Treat each imputed dataset separately\nnest() -&gt; Creates a list-column where each row contains one dataset (data column)\nmutate(fit = map(...)) -&gt; Iterate over the list of datasets, run the model on each one, and store the model object in a new list-column called fit.\n\n\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nRubin’s rule\n\nNow we can pool the results using the mitools package.\nsummary(mitools::MIcombine(imp_analysis$fit))\nYou can use coefs and vcovs, instead of fit.\n\n\nMore advanced coding\nYou can speed up your work by using data.table and speedglm.\nimp_long_dt &lt;- complete(imp_multi, action = \"long\")\nsetDT(imp_long_dt)\n\nlibrary(speedglm)\n\nimp_analysis &lt;- imp_long_dt[, {\n  # For each group, fit the logistic regression model\n  model &lt;- speedglm(death ~ dzclass + age + sex + edu + income + race + diabetes + wblc,\n                    family = binomial(), data = .SD)\n  # Return a list containing the coefficients and vcov matrix for this group\n  # These are wrapped in an outer list() to create list-columns.\n  list(coefs = list(coef(model)), vcovs = list(vcov(model)))\n}, by = .imp]\n\npooled_results &lt;- mitools::MIcombine(imp_analysis$coefs, imp_analysis$vcovs)\nsummary(pooled_results)",
    "crumbs": [
      "Home",
      "Content",
      "Lab 3"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "Welcome!\nThis website is a collection of lab materials for the EPID8313 course (2025). The labs are designed to help you practice and apply the concepts covered in the course.\nDuring each lab session (typically held before the journal club), I will address your specific questions using the resources provided here. To allow sufficient preparation time, please submit your questions at least one day in advance. If no questions are submitted, I will review the core concepts of the lab material for about 10–15 minutes before transitioning to the journal club.\nFor the journal club, you should prepare several slides summarizing the assigned articles. Each presentation will typically take around 15 minutes per article.\n\n\nInstroctor\n\nAki Shiroshita, MD, MPH\n4th-year Epidemiology PhD student\nOriginally from Japan\nFulbright grantee\nResearch interest: Environmental epidemiology, pharmacoepidemiology\nDissertation: Traffic-related environmental exposures during early life and adverse health outcomes",
    "crumbs": [
      "Home",
      "Content",
      "Overview"
    ]
  },
  {
    "objectID": "Assignment3.html",
    "href": "Assignment3.html",
    "title": "Assignment 3",
    "section": "",
    "text": "Comments on the assignment 3\n1. Confirm the causal assumptions\n\nConsistency\n\nThe observed outcome for an individual who received a particular treatment is the same as their potential outcome if they had been given that treatment.\nIf \\(X = i\\), \\(Y=Y^{x=i}\\)\n\nNo interference\n\nThe treatment received by one individual does not affect the outcome of another individual. In other words, my outcome only depends on my own treatment, not on anyone else’s.\n\\(Y^{x_1=i} \\neq Y^{x_1=i,x_2=j} \\rightarrow E[Y|{X=x}]=E[Y^{x}|{X=x}]\\)\n\nExchangeability\n\nThe treatment groups (e.g., treated vs. untreated) are comparable with respect to all factors that could influence the outcome, except for the treatment itself.\n\\(E[Y^{x}|{X=x}]=E(Y^{x})\\)\nIn observational studies, we usually assume the conditional exchangeability:\n\\(E[Y^{x}]=\\sum_Z E[Y^{x}|{X=x,Z}]=\\sum_Z E[Y^{x}|{X=x|Z}]=E(Y^x|Z=0)*P(Z=0)+E(Y^x|Z=1)*P(Z=1)+E(Y^x|Z=2)*P(Z=2)+....=E(E(Y^{x}|Z))\\)\n\nPositivity\n\nFor every set of characteristics a person might have, there is a non-zero probability of them receiving any of the treatment options.\n\\(E[Y^{x}]=\\sum_Z E[Y^{x}|{X=x,Z}]=\\sum_Z E[Y^{x}|{X=x|Z}]=E(Y^x|Z=0)*P(Z=0)+E(Y^x|Z=1)*P(Z=1)+E(Y^x|Z=2)*P(Z=2)+....=E(E(Y^{x}|Z))\\)\n2. Conduct the target trial emulation\n\nEligibility criteria\nTreatment strategies\nRandomized assignment\nStart/end of follow-up\nOutcomes\nCausal contrast\nAnalysis\n\nTo avoid immortal time bias, time zero should be defined such that:\n\nAll eligibility criteria are met\nTreatment strategies are assigned\nOutcome ascertainment begins\n\n\n\nPresentation\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Content",
      "Assignment 3"
    ]
  },
  {
    "objectID": "Assignment1.html",
    "href": "Assignment1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Comments on the assignment 1\n\nI prefer to provide a simple framework and/or figures alongside the text.\n\nQ1: the PECO format\nQ3: subject selection flow\nQ6: DAG\n\nInformation bias\n\nMeasurement error: mismeasurment of continuous variables (sometimes, random error, not systemic error, is called “measurement error”)\nMisclassification: inaccuracy of categorical variables (sometimes, this is called “information bias”)\n\n\nDAG may help understand the bias\n\nSelection bias\n\n\n\n\n\n\n\n\n\n\n\nMisclassification (Differentiality vs. Dependence)\n\n\nDifferentiality\nNondifferential: Sensitivity and specificity are independent of another key variable\nvs. \nDifferential: Sensitivity and specificity are not independent of another key variable\n\n\nDependence\nIndependent: Misclassification of one variable does not change the probability that subjects will be misclassified on a second variable\nvs. \nDependent: The probability of being doubly misclassified is not equal to the product of the probabilities of being singly misclassified with respect to exposure and outcome. (e.g., sensitivity of exposure misclassification is correlated with sensitivity of outcome misclassification)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPresentation\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Content",
      "Assignment 1"
    ]
  },
  {
    "objectID": "Assignment2.html",
    "href": "Assignment2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Comments on the assignment 2\n\nSignificant Digits (or significant figures)\n\nSignificant digits and decimal points are two different concepts. We usually use significant digits in scientific papers, although we prioritize adhere to the guidelines provided by the journal to which you are submitting.\nEnsure that significant digits are consistent and meaningful.\nFor example, someone said that decimal places in percentages may not provide meaningful information and rounding to a whole number may be better (e.g., \\(12.2\\)% \\(\\rightarrow\\) \\(12%\\))\nHow many significant digits are in the following numbers?\n\n\\(287\\)\n\nNon-zero digits are always significant.\n\n\\(50.03\\)\n\nZeros between non-zero digits are significant.\n\n\\(0.0045\\)\n\nLeading zeros (zeros at the beginning of a number) are never significant.\n\n\\(3.20 \\times 10^3\\)\n\nTrailing zeros (zeros at the end of a number) are significant only if the number contains a decimal point.\n\n\\(1,200.0\\)\n\n\n\n\n\n\n\nNote\n\n\n\nWhile tableone is excellent, gtsummary generally offers more flexible control for formatting by significant digits.\n\n\n\nsuppressPackageStartupMessages(library(tidyverse))\nlibrary(gtsummary)\nprostate &lt;- read.csv('https://raw.githubusercontent.com/AkiShiroshita/EPID813-2025--Lab/refs/heads/main/data/prostate.csv')\n\n# custom function\nfmt_sigfig &lt;- function(x, sigfig = 3) {\n  signif(x, sigfig)\n}\n\n# tbl_summary() applies whatever function you provide to format the numbers.\nprostate %&gt;%\n  dplyr::select(age, sbp, hg, ap) %&gt;%\n  gtsummary::tbl_summary(\n    statistic = all_continuous() ~ \"{mean} ({sd})\",\n    digits = all_continuous() ~ function(x) fmt_sigfig(x, sigfig = 3)\n  )\n\n\n\n\n\n\n\nCharacteristic\nN = 5021\n\n\n\n\nage\n71.5 (7.08)\n\n\n    Unknown\n1\n\n\nsbp\n14.4 (2.42)\n\n\nhg\n13.4 (1.95)\n\n\nap\n12.2 (62.2)\n\n\n\n1 Mean (SD)\n\n\n\n\n\n\n\n\n\nround()\n\nR uses round to even (also known as “bankers’ rounding”) to handle ties. This means that if the number to be rounded is exactly halfway between two possible rounded values, it rounds to the nearest even number.\nThe underlying behavior of tableone and gtsummaryis the same.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPresentation\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Content",
      "Assignment 2"
    ]
  },
  {
    "objectID": "Final_review.html",
    "href": "Final_review.html",
    "title": "Final review",
    "section": "",
    "text": "Q1: Although Cox regression is a semiparametric model, we can estimate the baseline hazard function. True or False?\n\n\n\n\n\nA: TRUE\nWhen we use Cox regression, we do not specify the baseline hazard function, which makes the model semiparametric. However, we can estimate the baseline hazard function based on the observed data and the results from the Cox model.\n\n\n\n::: {.callout-tip collapse=“true”} ### Q1: What is the difference between Generalized Estimating Equations (GEE) and Generalized Linear Mixed Models (GLMM)?\nI addressed this question in Lab 7.\n\nModeling correlation: GEE models within-subject correlation using a working correlation matrix, whereas GLMM models it through random effects.\n\nGEE assumes “block independence”\n\n\n\n\n\n\n\n\n\nRandom-intercept model\n\\(Y_{ij}=\\beta_0+\\beta_1 t_{ij} + b_{0i} + \\epsilon_{ij}=(\\beta_0 + b_{0i}) + \\beta_1 t_{ij} + \\epsilon_{ij}\\)\nRandom-slope model (random slope + intercept)\n\\(Y_{ij}=\\beta_0+\\beta_1 t_{ij} + b_{0i} + b_{1i}t_{ij} + \\epsilon_{ij}=(\\beta_0 + b_{0i}) + (\\beta_1 + b_{1i}) t_{ij} + \\epsilon_{ij}\\)\n\n\n\n\n\n\n\n\n\n\nUnlike GEE, which typically handles only one level of clustering, GLMM can model more complex hierarchical structures\n\ne.g., patients nested within hospitals and hospitals nested within regions\n\nAssumptions about missing data: GEE assumes data are missing completely at random (MCAR), while GLMM assumes data are missing at random (MAR)\n\nGLMM can provide valid parameter estimates under MAR, because it uses likelihood-based estimation that borrows information from other observed data. In many projects, some patients are lost to follow-up, but the model can still use the data from patients with complete or partial observations.\nOh the other hand, in GEE, if data are missing in a non-MCAR way, estimates may be biased unless you use methods like weighted GEE or multiple imputation.\n\nInference target: GEE estimates population-averaged (marginal) effects, whereas GLMM estimates subject-specific (conditional) effects.\n\ne.g., Mixed-effects logistic regression model provides odds ratio comparing the odds of death between a typical patient received treatment A and a typical patient of the same covariates received treatment B.\n“typical”: two subjects with the same random effect value.\ne.g., GEE provides an odds ratio comparing the odds of death if everyone received treatment A versus if everyone received treatment B.\nWhen the outcome is continuous and the identity link is used, population-averaged and subject-specific effects are identical.\nHowever, for binary and count outcomes, the two estimands differ. :::\n::: {.callout-tip collapse=“true”} ### Q1: In a target trial emulation using Medicare data to evaluate the effectiveness of colonoscopy in reducing colon cancer incidence among patients over 70 years old, the start of follow-up can be defined as the date of colonoscopy for the exposed group and the date of the first routine health check-up for the unexposed group. True or False?\nA: FALSE\nTo avoid immortal time bias, time zero should be defined such that:\n\nAll eligibility criteria are met\nTreatment strategies are assigned\nOutcome ascertainment begins\n\nI will not discuss what the best strategy is here, but the definition of time zero given above is incorrect (see lecture slides). :::\n::: {.callout-tip collapse=“true”} ### Q1: You want to evaluate the effectiveness of vitamin supplement X, a time-varying exposure (Yes vs. No), on yearly measured binary hospitalization outcomes (Yes vs. No at the X-year visit). Assuming there are no competing risks, should you use a mixed-effects logistic regression model or G-methods (e.g., a marginal structural model with inverse probability weighting)?\nA: G-methods\nWe should address the time-varying confounding affected by prior exposure (treament-confounder feedback). Mixed-effects logistic regression model cannot appropriately adjust for such confounding, whereas G-methods can. :::"
  },
  {
    "objectID": "Lab2.html",
    "href": "Lab2.html",
    "title": "Lab 2",
    "section": "",
    "text": "Lab 2 covers\n\ndata wrangling\nregression models.\n\n\nData wrangling\n\nbase R\ntidyverse: clean and readable\ndata.table: Optimized for speed and memory efficiency\n\n\n\n\n\n\n\nNote\n\n\n\nAs I use very large-scale environmental data, I am switching from tidyverse to data.table.\n\n\n\n\ntidyverse\nA philosophy created by Hadley Wickham\n\ndplyr → data manipulation (filter, mutate, group, summarize)\nggplot2 → data visualization\ntidyr → data tidying (reshaping, pivoting, separating)\nreadr → data import (CSV, TSV, etc.)\ntibble → modern data frames (better printing, easier handling)\npurrr → functional programming with lists (map, reduce)\nstringr → string handling\nforcats → categorical (factor) variables handling\n\n\n\n\n\n\n\nNote\n\n\n\nThe pipe function (takes the result of the expression on its left and “pipes” it into the function on its right) %&gt;% makes the workflow read like a sequence of steps.\n\n\nDemonstrations\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nMy tips and tricks\n\nFor moderate-sized datasets, I recommend using tidyverse for its readability.\nMemorize the basic commands for descriptive analyses.\nCheck the unique values and summaries of each column (e.g., unique(), summary())\nCheck a lot of contingency tables (e.g., table())\nVisualize the variables as needed (e.g., ggplot())\n\n\n\ndata.table (advanced)\n \n\nDT[i, j, by]\n\n\nWhere DT is a data.table object, the i argument is used for filtering and joining, the j argument is used for summarizing and transforming, and the by argument defines the groups to which to apply these operations.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nConvert objects to data.table:\n\nsetDT() vs. as.data.table()\nsetDT(): Converts in place\nas.data.table(): Creates a new data.table object\n\nFilter rows\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nChange data type\n\nModify-in-place\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nMake new columns\n\nModify-in-place\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nSummarize by group\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPiping\n\nIt takes the result of the expression on its left and “pipes” it into the function on its right.\nAfter R 4.3.0, the native pipe supports a _ placeholder to the right-hand side of the pipe.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPoisson regression\n\nConventional Poisson regression\n\nFor count data\n\\(log(E[Y_i|X_i])=\\beta_0+\\beta_1X_i+log(T_i)\\)\nEffect measure: rate ratio\n\nModified Poisson regression\n\nFor binary data\n\\(log(E[Y_i|X_i])=\\beta_0+\\beta_1X_i\\)\nEffect measure: risk ratio\n\n\n\n\n\n\nNote\n\n\n\nRobust standard errors are recommended in both the conventional Poisson and the modified Poisson regression models.\n\n\n\n\nRegression models (advanced)\nspeedglm package: more speedy than glm\nIt directly solves the normal equations of the weighted least squares problem at each iteration (rather than relies on a QR decomposition).\nWhy does this important?\n\\(\\rightarrow\\) In G-methods, you often create many derived variables and fit many regression models across “copied” datasets.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Content",
      "Lab 2"
    ]
  },
  {
    "objectID": "Lab4.html",
    "href": "Lab4.html",
    "title": "Lab 4",
    "section": "",
    "text": "Lab 4 covers\n\nPower and sample size calculation\n\nIn many cases, we want to perform power calculations for multivariable regression models.\n\n\n\n\n\n\nNote\n\n\n\nPower = probability of rejecting the null hypothesis if a specific alternative is true\n\n\n\nBrief overview of software\n\nR packages: pwr, pwrss, etc.\nSTATA\nSAS Proc Power\nPS: Power and Sample Size Calculation (Vanderbilt University, free): https://cqsclinical.app.vumc.org/ps/\nG*Power (free, less intuitive): https://www.psychologie.hhu.de/arbeitsgruppen/allgemeine-psychologie-und-arbeitspsychologie/gpower\nPASS (NCSS, commercial, most flexible): https://www.ncss.com/software/pass/\nEPI Info (CDC, free): https://www.cdc.gov/epiinfo/index.html\nOptimal Design (free, program for multilevel modeling): https://www.wtgrantfoundation.org/resources/optimal-design\nFor conducting complex statistical analyses (e.g., propensity score analysis), I recommend using Monte Carlo simulations.\n\n\n\nR pwrss package\nTutorial: https://rpubs.com/metinbulus/pwrss\nPower and sample size calculation based on the Wald test.\nScenario: You are planning a study where the outcome is binary and will be analyzed with logistic regression.\nWhat you need is\n\np0: probability of the outcome when the predictor is at reference level (e.g., control group).\np1: probability of the outcome when the predictor is at the exposure level (e.g., treatment group).\nr2.other.x: A squared multiple correlation between an exposure and other covariates\n\nHigher values indicate more correlation, which will increase the required sample size.\nYou can calculate r2.other.x by fitting a linear regression model where your main predictor of interest is treated as the outcome and all other covariates are the predictors.\nfit &lt;- lm(exposure ~ cov1+cov2, data = data)\n# Extract the R-squared value\nsummary_model &lt;- summary(fit)\nr2_estimate &lt;- summary_model$r.squared\n\ndist: distribution of the predictor (e.g., normal, bernoulli, etc.)\nn: total sample size\nalpha = 0.05: significance level\n\n\npwrss::pwrss.z.logreg(\n  p0 = 0.11,\n  p1 = 0.10,\n  r2.other.x = 0.10,\n  dist = list(dist = \"normal\", mean = 10, sd = 2),\n  n = 8000,\n  alpha = 0.05\n)\n\n+--------------------------------------------------+\n|                POWER CALCULATION                 |\n+--------------------------------------------------+\n\nLogistic Regression Coefficient (Wald's Z-Test)\n\n  Method          : Demidenko (Variance Corrected)\n  Predictor Dist. : Normal\n\n---------------------------------------------------\nHypotheses\n---------------------------------------------------\n  H0 (Null Claim) : Odds Ratio = 1\n  H1 (Alt. Claim) : Odds Ratio != 1\n\n---------------------------------------------------\nResults\n---------------------------------------------------\n  Sample Size          = 8000\n  Type 1 Error (alpha) = 0.050\n  Type 2 Error (beta)  = 0.050\n  Statistical Power    = 0.95  &lt;&lt;\n\n\n\nExample writing of your method section\n\n\nFor our primary analysis, a sample size of 8,000 provides approximately 81% power to detect an odds ratio of 0.90 for PM2.5, assuming a baseline outcome prevalence of 11% and a normally distributed PM2.5 exposure (mean = 10, SD = 2). This calculation was performed using a two-sided z-test at a significance level of 0.05 and accounts for potential confounding by assuming that other covariates explain 10% of the variance in the exposure (i.e., a squared multiple correlation of 0.1 between the primary exposure and other covariates)\n\n\n\n\n\n\n\nNote\n\n\n\n\nOdds for the reference group: \\(0.11/(1−0.11)=0.1236\\)\nOdds for the comparison group: \\(0.10/(1−0.10)=0.1111\\)\nOdds Ratio \\(= 0.1111/0.1236 \\approx 0.90\\)",
    "crumbs": [
      "Home",
      "Content",
      "Lab 4"
    ]
  },
  {
    "objectID": "Lab6.html",
    "href": "Lab6.html",
    "title": "Lab 6",
    "section": "",
    "text": "Lab 6 covers\n\nSurvival analysis\n\n\nKaplan-Meier curve and Risk set\n\nThe interval in the survival analysis is (start, stop] (open on the left and closed on the right).\n\ne.g., (0, 10] means from just after time 0 to and including time 10.\nDo you find any unusual points in this Kaplan-Meier curve?\n\n\n\n\n\n\n\n\n\nCall: survfit(formula = Surv(surv_yy, death_all) ~ 1, data = colon_clean)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n  0.0  15564    5475    0.648 0.00383        0.641        0.656\n  1.5  10089    1886    0.527 0.00400        0.519        0.535\n  2.5   7536     919    0.463 0.00404        0.455        0.471\n  3.5   6114     609    0.417 0.00404        0.409        0.425\n  4.5   5028     456    0.379 0.00405        0.371        0.387\n  5.5   4210     356    0.347 0.00404        0.339        0.355\n  6.5   3511     254    0.322 0.00405        0.314        0.330\n  7.5   2939     196    0.300 0.00406        0.292        0.308\n  8.5   2476     158    0.281 0.00407        0.273        0.289\n  9.5   2085     146    0.261 0.00410        0.254        0.270\n 10.5   1725     105    0.246 0.00414        0.238        0.254\n 11.5   1447      90    0.230 0.00418        0.222        0.239\n 12.5   1177      74    0.216 0.00424        0.208        0.224\n 13.5    957      48    0.205 0.00431        0.197        0.214\n 14.5    735      42    0.193 0.00442        0.185        0.202\n 15.5    559      36    0.181 0.00460        0.172        0.190\n 16.5    421      35    0.166 0.00487        0.157        0.176\n 17.5    293      15    0.157 0.00509        0.148        0.168\n 18.5    211       7    0.152 0.00529        0.142        0.163\n 19.5    132      12    0.138 0.00613        0.127        0.151\n 20.5     56       3    0.131 0.00714        0.118        0.146\n\n\n\n\n\n\n\n\nQ: In a randomized controlled trial, we included 1,000 patients and conducted a longitudinal follow-up to assess the hazard ratio of death between Treatment A and Treatment B. We found 10 patients died on day 0, the same day the follow-up period began. Should we excluded these 10 patients?\n\n\n\n\n\nAnswer: It depends.\nIf the follow-up began around 8 a.m. and the patients died around 11 p.m., they could be included in the analysis (for example, by assigning a small value such as 0.5 days instead of 0 days). However, if the follow-up started around 1 p.m. and the patients died before that time, they should be excluded.\n\\(\\rightarrow\\) We require detailed information on timing and/or the application of consistent criteria across all patients in the cohort.\n\ndata(colon, package = \"biostat3\")\ncolon_clean &lt;- colon %&gt;%\n  mutate(\n    # 1 if dead from any cause, 0 if alive (censored)\n    death_all = if_else(status == \"Alive\", 0, 1) \n  )\n\n# Fit the Kaplan-Meier curve for the whole population\nkm_fit_overall &lt;- survfit(Surv(surv_yy, death_all) ~ 1, data = colon_clean)\n\n# Use ggsurvplot for a publication-quality plot\nggsurvplot(\n  km_fit_overall,\n  data = colon_clean,\n  risk.table = TRUE,       # Add a risk table below the plot\n  conf.int = TRUE,         # Show confidence intervals\n  xlab = \"Years Since Diagnosis\",\n  ylab = \"Overall Survival Probability\",\n  title = \"Kaplan-Meier Curve for Overall Survival\",\n  risk.table.y.text = FALSE,\n  ggtheme = theme_light()\n)\n\nIgnoring unknown labels:\n• fill : \"Strata\"\nIgnoring unknown labels:\n• fill : \"Strata\"\nIgnoring unknown labels:\n• fill : \"Strata\"\nIgnoring unknown labels:\n• fill : \"Strata\"\nIgnoring unknown labels:\n• colour : \"Strata\"\n\n\n\n\n\n\n\n\nsummary(km_fit_overall)\n\nCall: survfit(formula = Surv(surv_yy, death_all) ~ 1, data = colon_clean)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n  0.5  15564    5475    0.648 0.00383        0.641        0.656\n  1.5  10089    1886    0.527 0.00400        0.519        0.535\n  2.5   7536     919    0.463 0.00404        0.455        0.471\n  3.5   6114     609    0.417 0.00404        0.409        0.425\n  4.5   5028     456    0.379 0.00405        0.371        0.387\n  5.5   4210     356    0.347 0.00404        0.339        0.355\n  6.5   3511     254    0.322 0.00405        0.314        0.330\n  7.5   2939     196    0.300 0.00406        0.292        0.308\n  8.5   2476     158    0.281 0.00407        0.273        0.289\n  9.5   2085     146    0.261 0.00410        0.254        0.270\n 10.5   1725     105    0.246 0.00414        0.238        0.254\n 11.5   1447      90    0.230 0.00418        0.222        0.239\n 12.5   1177      74    0.216 0.00424        0.208        0.224\n 13.5    957      48    0.205 0.00431        0.197        0.214\n 14.5    735      42    0.193 0.00442        0.185        0.202\n 15.5    559      36    0.181 0.00460        0.172        0.190\n 16.5    421      35    0.166 0.00487        0.157        0.176\n 17.5    293      15    0.157 0.00509        0.148        0.168\n 18.5    211       7    0.152 0.00529        0.142        0.163\n 19.5    132      12    0.138 0.00613        0.127        0.151\n 20.5     56       3    0.131 0.00714        0.118        0.146\n\n\n\n\n\n\nDescribe a Kaplan-Meier curve manually.\n\n\n\n\n\n\n\n\n\n\nRules in KM curve\n\nDivide intervals at the time the event occurs\nCensoring within an interval is subtracted from the risk set at the end of the interval\nIf censoring and the event occur at the same time, censoring is assumed to occur immediately after the event.\n\n\n\n\n\n\nTime\nRisk.set\nN.of.events\nInterval.specific.event.rate\n\n\n\n\n(0,0.25]\n?\n?\n?\n\n\n(0.25,0.5]\n?\n?\n?\n\n\n(0.5,1.0]\n?\n?\n?\n\n\n(1.0,1.5]\n?\n?\n?\n\n\n(1.5,2.0]\n?\n?\n?\n\n\n\n\n\n\n\n\n\n\n\nQ: Fill in the blanks.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime\nRisk.set\nN.of.events\nInterval.specific.event.rate\n\n\n\n\n(0,0.25]\n9\n1\n0.111\n\n\n(0.25,0.5]\n8\n1\n0.125\n\n\n(0.5,1.0]\n7\n2\n0.286\n\n\n(1.0,1.5]\n5\n1\n0.200\n\n\n(1.5,2.0]\n3\n2\n0.667\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProportional hazards assumption\nWhen you check the proportional hazards assumption, ensure that categorical variables are converted to dummy variables beforehan.\nOr you may acknowledge that term=TRUE (default) in cox.zph() function checks the proportional hazards assumption for each variable as a whole, while term=FALSE checks it for each level of the categorical variable.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nCounting process data (Advanced topic)\nMainly for extended Cox regression model (time-varying exposure)\n\nWide-format data\n\n\n\n\n\n\n\n\n\n\n\n\n患者ID\nTreatment\nTime to treatment\nEvent indicator\nTime to death\n\n\n\n\n1\n1\n13\n1\n30\n\n\n2\n0\nNA\n0\n30\n\n\n\n\n\nWhat is counting process data?\n\nLong-format data data where the exposure remains the same from the beginning to the end of the interval, and the outcome occurs at the end of the interval.\n(start, stop]: open on the left and closed on the right\n\n\n\n\n\n\n\n\n\n\n\n患者ID\nStart\nStop\nTreatment\nDeath\n\n\n\n\n1\n0\n13\n0\n0\n\n\n1\n13\n30\n1\n1\n\n\n2\n0\n30\n0\n0\n\n\n\n\n\n\n\n\n\n\nQ: We found that some patients received treatment at time 13 and died on the same day. Should we classify them as exposed?\n\n\n\n\n\nAnswer: Again, it depends.\nIf the treatment began around 8 a.m. and the patients died around 11 p.m., they could be classified as “exposed” in the analysis (for example, by subtracting a small value from 13). However, if the treatment started around 1 p.m. and the patients died before that time, they should not be classified as “exposed”.\n\\(\\rightarrow\\) We require detailed information on timing and/or the application of consistent criteria across all patients in the cohort.",
    "crumbs": [
      "Home",
      "Content",
      "Lab 6"
    ]
  },
  {
    "objectID": "Lab8.html",
    "href": "Lab8.html",
    "title": "Lab 8",
    "section": "",
    "text": "Lab 8 covers\n\nEffect measure modification\nMediation\n\n\n\n\n\n\n\nQ1: Is the following statement true?: “Effect modification can be present with no interaction. Interaction can be present with no effect modification.”\n\n\n\n\n\nA: TRUE\nSee VanderWeele 2009.\nInteraction may be used to describe instances in which potential interventions on a secondary exposure are in view (i.e., considers counterfactual outcome intervening on both exposures), while effect modification may be used to describe instances in which merely conditioning on a secondary exposure is in view (i.e., considers counterfactual outcome intervening on one exposure only).\nExamples:\n\nEffect modifier: Gene × Environment interaction (the gene is not modifiable, but the environment may be modifiable)\nInteraction: Medication × Medication interaction (both medications are modifiable)\n\nThe distinction depends on the conceptual framework of your study.\nFormulas:\n\nEffect modifier: \\(E[D_{e1}|Q=q_1,X=x]-E[D_{e0}|Q=q_1,X=x] \\neq E[D_{e1}|Q=q_0,X=x]-E[D_{e0}|Q=q_0,X=x]\\)\nInteraction: \\(E[D_{e_1,q_1}|X=x]-E[D_{e_0,q_1}|X=x] \\neq E[D_{e_1,q_o}|X=x]-E[D_{e_0,q_0}|X=x]\\)\n\nWhere there are 2 levels of E ( \\(e_0\\) and \\(e_1\\) ), and 2 levels of Q ( \\(q_0\\) and \\(q_1\\) )\nIn other words, when investigating interaction, you need to account for confounders between \\(E\\) and \\(D\\) as well as those between \\(Q\\) and \\(D\\). In contrast, when focusing on effect modification, adjustment for confounders between \\(E\\) and \\(D\\) may be sufficient.\n\n\n\nSuppose the table below represents the number of outcomes within each exposure group:\nExposure 2 = Yes\n\n\n\n\nCases\nControls\nTotal\n\n\n\n\nExposure 1 +\n20\n80\n100\n\n\nExposure 1 -\n10\n90\n100\n\n\n\nExposure 2 = No\n\n\n\n\nCases\nControls\nTotal\n\n\n\n\nExposure 1 +\n30\n70\n100\n\n\nExposure 1 -\n20\n80\n100\n\n\n\n\n\n\n\n\n\nQ2: Is there evidence of additive or multiplicative interaction?\n\n\n\n\n\nA:\nFirst, calculate the risks across all the combination of exposure 1 and exposure 2.\n\n\n\n\nExposure 2 +\nExposure 2 -\n\n\n\n\n\nExposure 1 +\n0.2\n0.3\n\n\n\nExposure 1 -\n0.1\n0.2\n\n\n\n\nCalculate the following outcomes under:\n\nFirst exposure only\nSecond exposure only\nBoth exposures\nNeither exposure\n\nUsing these risks, we can calculate additive and multiplicative interactions.\n\nAdditive interaction (the extent to which of the two exposures together exceeds the effect of each considered individually on the additive scale measure):\n\n\\((p_{11}-p_{00})-[(p_{10}-p_{00})+(p_{01}-p_{00})]=p_{11}-p_{10}-p_{01}+p_{00}=0.2-0.3-0.1+0.2=0\\)\n\\(\\rightarrow\\) No superadditive and supadditive interactions\n\\(RR_{10}=p_{10}/p_{00}\\)\n\\(RR_{01}=p_{01}/p_{00}\\)\n\\(RR_{11}=p_{11}/p_{00}\\)\n\nMultiplicative interaction(the extent to which of the two exposures together exceeds the effect of each considered individually on the multiplicative scale measure): \\(\\frac{RR_{11}}{RR_{10} \\times RR_{01}}=\\frac{p_{11}p_{00}}{p_{10}p_{01}}=\\frac{0.2 \\times 0.2}{0.1 \\times 0.3} \\approx 1.33\\)\n\n\\(\\rightarrow\\) Supermultiplicative\n\n\n\n\nAdditive vs. multiplicative interaction\n\nWhat outcome scale are you referring to?\n\ne.g., A logistic regression model\n\\(logit(Pr(Y=1|X_1,X_2))=\\beta_0+\\beta_1X_1+\\beta_2X_2+\\beta_3X_1X_2\\)\nglm(outcome ~ exposure1 + exposure2 + exposure1:expsoure2,\nfamily = binomial(link = \"logit\"), data = data)\n\n\n\n\n\n\nQ: Does \\(\\beta_3\\) represent an additive or multiplicative interaction?\n\n\n\n\n\nAnswer: On the logit scale ( \\(\\beta_3\\) ), it is additive, whereas on the odds ratio scale, it is multiplicative.\nInteraction or effect measure modification = “Different treatment effects dependent on other variables”\n\n\n\n\n\n\n\n\n\nTreatment effects are linear on a log-odds scale, while the probability of the outcomes changes depending on other variables without interaction terms.\nThe left figure illustrates a logistic regression model with an interaction term (on a logit scale), whereas the right figure shows a model without an interaction term (on a probability scale).\n\\(\\rightarrow\\) Nonlinear regression analyses show an inherent interaction! (An interaction term does not necessarily indicate “interaction”)\nWe should be cautious about the outcome scales.\n\\(\\rightarrow\\) This is the motivation for the weighting approach (marginal structural model).",
    "crumbs": [
      "Home",
      "Content",
      "Lab 8"
    ]
  },
  {
    "objectID": "MA_Lab.html",
    "href": "MA_Lab.html",
    "title": "Meta-analysis Lab",
    "section": "",
    "text": "You are supervising a medical student conducting a systematic review and meta-analysis of RCTs on the effects of a new drug X (vs. placebo) on some QOL scores (e.g., SF36 [0-100], EQ-5D [-0.594 to 1.0], etc). The student has gathered data from the included studies, however, the reporting formats differ across studies. The student is uncertain about how to proceed with the meta-analysis.\n\n\n\n\n\n\nQ1: What effect size measure would you use for the meta-analysis? Why?\n\n\n\n\n\nAnswer: Standardized mean difference (SMD) because the QOL scores are measured on different scales across studies, and SMD allows for comparison by standardizing the differences.\nOption A: Meta-analysis of QOL scores at the follow-up visit\nIf randomization worked and baseline means are similar, this is usually acceptable.\nOption B: Meta-analysis of change scores (follow-up minus baseline) in QOL scores\nFrom here,\nbecause change scores in QOL scores are not reported in many studies, you decided to focus on Option A.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ2: Study A reported the standardized mean difference (SMD) and its standard error (SE), comparing follow-up scores between the treatment and control groups. However, it reported a “strange” happiness score ranging from -50 to 50, where lower scores indicate better QOL (In other QOL scores, higher scores indicate better QOL). Can this study be included in the meta-analysis?\n\n\n\n\n\nAnswer: Yes.\nYou can include this study by reversing the sign of the SMD and its SE.\n\n\n\n\n\n\n\n\n\nQ3: Study B did not report the standardized mean difference (SMD) or its standard error (SE). However, it provided the mean and standard deviation (SD) for both the drug X and placebo groups at the follow-up visit. Can this study still be included in the meta-analysis?\n\n\n\n\n\nAnswer: Yes.\n\\(SMD=\\frac{Mean_{Drug}-Mean_{Placebo}}{SD_{pooled}}\\)\nwhere\n\\(SD_{pooled}=\\sqrt{\\frac{(n_1-1)SD^2_1 + (n_2-1)SD^2_2}{n_1+n_2-2}}\\)\nThen, SE of SMD can be calculated as:\n\\(SE_{SMD}=\\sqrt{\\frac{n_1+n_2}{n_1 n_2}+\\frac{SMD^2}{2(n_1+n_2-2)}}\\)\n(There are other formulas for SE of SMD. This is one of the commonly used formulas.)\nPlease note that you do not use SMD for pre- and post- comparisons within the same group.\n\\(SMD = \\frac{Mean_{post}-Mean_{pre}}{SD_{change}}\\)\nwhere \\(SD_{change}\\) : standard deviation of the change scores\nor \\(SD_{change}=\\sqrt{SD^2_{pre}+SD^2_{post}-2 \\times r \\times SD_{pre} \\times SD_{post}}\\)\n(You need correlation coefficient \\(r\\) )\n\n\n\n\n\n\n\n\n\nQ4: Study C did not report SMD and its standard error (SE). However, it reported the mean difference (MD) and SE(MD) between the drug X and placebo groups at the follow-up visit. The means and standard deviations (SDs) for the drug X and placebo groups at follow-up are not available. Are you able to use this study in the meta-analysis?\n\n\n\n\n\nAnswer: Yes.\n\\(SMD=\\frac{Mean_{Drug}-Mean_{Placebo}}{SD_{pooled}}\\)\nwhere\n\\(SD_{pooled}=\\sqrt{\\frac{(n_1-1)SD^2_1 + (n_2-1)SD^2_2}{n_1+n_2-2}}\\)\nThen, SE of SMD can be calculated as:\n\\(SE_{SMD}=\\sqrt{\\frac{n_1+n_2}{n_1 n_2}+\\frac{SMD^2}{2(n_1+n_2-2)}}\\)\nIf you do not have SDs, you cannot directly compute SMD.\nHowever, you can approximate SMD if you have a “reasonable” estimate of the SD from other studies.:\n\\(SMD \\approx \\frac{MD}{SD_{reference}}\\)\nand adjust SE accordingly:\n\\(SE_{SMD} \\approx \\frac{SE_{MD}}{SD_{reference}}\\)\nThere is no clear rule for this, as the evidence is based on case series. In general, we select a study with a similar design, sample size, and other relevant characteristics.\n\nThe simplest imputation is to borrow the SD from one or more other studies. Furukawa and colleagues found that imputing SDs either from other studies in the same meta-analysis, or from studies in another meta-analysis, yielded approximately correct results in two case studies (Furukawa et al 2006). If several candidate SDs are available, review authors should decide whether to use their average, the highest, a ‘reasonably high’ value, or some other strategy. For meta-analyses of MDs, choosing a higher SD down-weights a study and yields a wider confidence interval. However, for SMD meta-analyses, choosing a higher SD will bias the result towards a lack of effect. More complicated alternatives are available for making use of multiple candidate SDs. For example, Marinho and colleagues implemented a linear regression of log(SD) on log(mean), because of a strong linear relationship between the two (Marinho et al 2003).\n\nhttps://www.cochrane.org/authors/handbooks-and-manuals/handbook/current/chapter-06\n\n\n\n\n\n\n\n\n\nQ5: Study D reported Cohen’s d comparing pre- and post-intervention QOL scores within both the treatment and control groups. Can this study be included in the meta-analysis?\n\n\n\n\n\nAnswer: No.\nIn Q1, you decided to focus on Option A (meta-analysis of QOL scores at the follow-up visit). Therefore, pre-post comparisons within the same group cannot be used for this meta-analysis.\nIf this study reported Cohen’s d comparing the drug X and placebo groups at follow-up, then it could be included, even if SD or SE of Cohen’s d were not reported.\n\\(SE_{SMD}=\\sqrt{\\frac{n_1+n_2}{n_1 n_2}+\\frac{SMD^2}{2(n_1+n_2-2)}}\\)\n(There are other formulas for SE of SMD. This is one of the commonly used formulas.)"
  },
  {
    "objectID": "References.html",
    "href": "References.html",
    "title": "References",
    "section": "",
    "text": "Providing p-values in Table 1: https://pmc.ncbi.nlm.nih.gov/articles/PMC4877414/\nBenchmarks for interpreting R² values\n\nCohen (1988): Cohen, J. 1988. Statistical Power Analysis for the Behavioral Sciences, 2nd Ed. New York: Routledge. https://www.taylorfrancis.com/books/mono/10.4324/9780203771587/statistical-power-analysis-behavioral-sciences-jacob-cohen\n\\(R^2 &lt; 0.02\\) → Very weak\n\\(0.02 ≤ R^2\\) &lt; 0.13 → Weak\n\\(0.13 ≤ R^2\\) &lt; 0.26 → Moderate\n\\(R^2 ≥ 0.26\\) → Substantial\nFalk & Miller (1992): Falk, R Frank, and Nancy B Miller. 1992. A Primer for Soft Modeling. University of Akron Press.\n\\(R^2 &lt; 0.10\\) → Negligible\n\\(R^2 ≥ 0.10\\) → Adequate\n\nA practical reference of self-controlled case series: http://sccs-studies.info/index.html\nScoping review of biases in database research: https://pubmed.ncbi.nlm.nih.gov/30871502/\nGail 1972 is the first to highlight people’s interest in immortal time bias: https://pubmed.ncbi.nlm.nih.gov/4554414/\n\nIn the field of pharmacoepidemiology, this study of COPD and inhaled corticosteroid became a catalyst for attracting attention: https://pubmed.ncbi.nlm.nih.gov/11520719/\nCritique: https://pubmed.ncbi.nlm.nih.gov/12663327/\nValidation by RCT: https://www.nejm.org/doi/full/10.1056/NEJMoa063070\n\nSimulation study focused on outcome imputation: https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-016-0281-5\n\nAlthough the method that imputes the outcome of interest and then removes observations where the outcome is imputed performed slightly better in some scenarios, especially for low and moderate levels of missingness, it was not always better and it is known to be biased in the presence of auxiliary variables. For very high levels of missingness, the higher power obtained when imputing the outcome (and not dropping observations) might make this approach somewhat more appealing.\n\nIPCW: https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-022-01533-9\nControversy regarding sample size and power calculation in observation studies: https://pubmed.ncbi.nlm.nih.gov/34461211/\nMatching in cohort studies: https://pubmed.ncbi.nlm.nih.gov/23761197/\nPaired nature of the data in propensity-score matching: https://pubmed.ncbi.nlm.nih.gov/18038446/\n\nI recommend reviewing the associated comments on this article.\n\nCompeting risk1: https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1765783\nCompeting risk2: https://pubmed.ncbi.nlm.nih.gov/31985089/\nThe hazards of hazard ratios: https://pmc.ncbi.nlm.nih.gov/articles/PMC3653612/\nA issue of ggcoxzph: https://github.com/kassambara/survminer/issues/454\nImputation in longitudinal studies: https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-018-0615-6\nReporting guideline of target trial emulation: fbclid=IwY2xjawNs2lhleHRuA2FlbQIxMQBicmlkETFmRkt3RXNpaWpsdzNzeGJnAR4WHcMuyjIQBm5vyDUZzQyEg4BRP5p_gJTUIg9nmrwgm_aoFUrqIg3WnI0ULg_aem_oj318d8c-ogCvW7Erz-FcA\nCompeting events:\n\nEffect on a composite outcome\nTotal effect: Interpret the competing events as an event which prevents the development of the outcome thereafter (assign a value of 0 to the outcome variable after an individual has dies and estimate the total effect of the vaccine on the outcome = what is the effect of vaccination with a first dose of the CROWN vaccine at baseline vs. no vaccination at baseline on the 24-week risk of coronavirus hospitalization, had no one been lost to follow-up?)\nControlled direct effect: Interpret the competing event as a censoring event (implies an intervention on death = what is the effect of vaccination with a first dose of the CROWN vaccine at baseline vs. no vaccination at baseline on the 24-week risk of coronavirus hospitalization, had no one died or been lost to follow-up?)\nSeparable direct effect\nSurvivor average causal effect\n\n\n\nDifference between causal mediation analysis and conventional mediation analysis\n\nCan incorporate confounders of the mediator-outcome relationship\nCan incorporate interactions between the effects of the exposure and the mediator\n\n\n\n\n\n\n\n\n\n\n\n\nInterpration of natural direct and indirect effects\n\nControlled direct effect (CDE): Set the mediator to a reference value \\(M=m\\) uniformly for everyone in the population\n\nfit_outcome &lt;- lm(outcome ~ mediator + treatment + covariates, data = data)\n# predict the outcome\npred_y1 &lt;- predict(fit_outcome, newdata = data.frame(treatment = 1,\n                                                     mediator = 0,\n                                                     covariates = w))\npred_y0 &lt;- predict(fit_outcome, newdata = data.frame(treatment = 0,\n                                                     mediator = 0,\n                                                     covariates = w))\n# CDE (fix mediator = 0)\nmean(pred_y1 - pred_y0)\n\nNatural direct effect (NDE): Varying treatment while keeping the mediator fixed at the value it would have taken under no treatment\n\nComparing the effects of \\(A=1\\) versus \\(A=0\\), setting \\(M=M_0\\)\nfit_outcome &lt;- lm(outcome ~ mediator + treatment + covariates, data = data)\n# NDE (letting mediator take the observed values)\npred_y1 &lt;- predict(fit_outcome, newdata = data.frame(treatment = 1,\n                                                     mediator = m,\n                                                     covariates = w))\npred_y0 &lt;- predict(fit_outcome, newdata = data.frame(treatment = 0,\n                                                     mediator = m,\n                                                     covariates = w))\ndiff &lt;- pred_y1 - pred_y0\n# fit a model to estimate E[diff|treatment, covariates]\nfit_diff &lt;- lm(diff ~ treatment + covariates, data = data)\n# predict the value of the \"diff\" under treatment = 0\npred_diff &lt;- predict(diff, newdata = data.frame(treatment = 0,\n                                                covariates = w))\n# NDE\nmean(pred_pseudo)\n\nNatural indirect effect (NIE): Varying the mediator from the value it would have taken under treatment to the value it would have taken under control, while keeping treatment fixed\n\nComparing the effects of \\(M=M_1\\) versus \\(M=M_0\\), setting \\(A=1\\)\nfit_mediator &lt;- lm(mediator ~ treatment + covariates, data = data)\n# predict mediator values under treatment = 1 and treatment = 0\nm1 &lt;- predict(fit_mediator, newdata = data.frame(treatment = 1,\n                                                 covariates = w))\nm0 &lt;- predict(fit_mediator, newdata = data.frame(treatment = 0,\n                                                 covariates = w))\n# predict the outcome\ny1_m1 &lt;- predict(fit_outcome, newdata = data.frame(treatment = 1,\n                                                   mediator = m1,\n                                                   covariates = w))\ny1_m0 &lt;- predict(fit_outcome, newdata = data.frame(treatment = 1,\n                                                   mediator = m0,\n                                                   covariates = w))\n# NIE\nmean(y1_m1 - y1_m0)\n\n\nAssumptions of natural direct and indirect effects\n\nThere are no unmeasured exposure-outcome confounders given \\(C\\)\nThere are no unmeasured mediator-outcome confounders given \\(C\\) and \\(A\\)\nThere are no unmeasured exposure-mediator confounders given \\(C\\)\nThere is no mediator-outcome confouder affected by exposure\n\nFor controlled direct effects, only first two assumptions are needed.\n\n\nWeighting approach (mediation)\n\nFirst, create a new dataset which has two copies of each individual\nCreate a additional new variables we will call \\(A^*\\)\nThe variable \\(A^*\\) is set equal to \\(A\\) for the first copy of the individual\nThe variable \\(A^*\\) is set equal to \\(1-A\\) for the second copy of the individual\n\n\\(w^A_i=\\frac{P(A=a_i)}{P(A=a_i|C=c_i)}\\)\n\\(w^M_i=\\frac{P(M=m_i|A=a^*_i, C=c_i)}{P(A=a_i|A=a_i, C=c_i)}\\)\nThe numerator is the predicted probability of having the value of the mediator that the individual in fact had a value of the exposure which was in fact equal to \\(A=a^*\\) (i.e., equal to what the individual actually had for the first replication and to 1 minus this value for the second replication)\nOverall weight: \\(w_i=w^A_i \\times w^M_i\\)\n\n\nWeighting approach (interaction [not effect modification])\nExposure 1: \\(E\\) , exposure 2: \\(Q\\)\n\\(w^E_i=\\frac{P(E=e_i|Q=q_i)}{P(E=e_i|Q=q_i, X=x_i)}\\)\n\\(w^Q_i=\\frac{P(Q=q_i)}{P(Q=q_i|X=x_i)}\\)\nOverall weight: \\(w_i=w^A_i \\times w^M_i\\)"
  }
]