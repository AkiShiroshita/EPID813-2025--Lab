[
  {
    "objectID": "slide-embed.html",
    "href": "slide-embed.html",
    "title": "Embed Slides",
    "section": "",
    "text": "On this page, we show how we can embed a RevealJS Presentation inside of a Quarto Website."
  },
  {
    "objectID": "slide-embed.html#presentation",
    "href": "slide-embed.html#presentation",
    "title": "Embed Slides",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nFor quarto-webr to work within RevealJS, you must use a pre-release version of Quarto that is 1.4.502 or greater that contains an updated copy of pandoc. For more details, please see Issue #14."
  },
  {
    "objectID": "slide-embed.html#embed-code",
    "href": "slide-embed.html#embed-code",
    "title": "Embed Slides",
    "section": "Embed Code",
    "text": "Embed Code\nPlace the following code inside of the Quarto Document:\n&lt;style&gt;\n.slide-deck {\n    border: 3px solid #dee2e6;\n    width: 100%;\n    height: 475px;\n}\n&lt;/style&gt;\n\n&lt;div&gt;\n```{=html}\n&lt;iframe class=\"slide-deck\" src=\"path/to/presentation/\"&gt;&lt;/iframe&gt;\n```\n&lt;/div&gt;"
  },
  {
    "objectID": "Lab2.html",
    "href": "Lab2.html",
    "title": "Lab 2",
    "section": "",
    "text": "Lab 2 covers\n\ndata wrangling\nregression models.\n\n\nData wrangling\n\nbase R\ntidyverse: clean and readable\ndata.table: Optimized for speed and memory efficiency\n\n\n\n\n\n\n\nNote\n\n\n\nAs I use very large-scale environmental data, I am switching from tidyverse to data.table.\n\n\n\n\ntidyverse\nA philosophy created by Hadley Wickham\n\ndplyr → data manipulation (filter, mutate, group, summarize)\nggplot2 → data visualization\ntidyr → data tidying (reshaping, pivoting, separating)\nreadr → data import (CSV, TSV, etc.)\ntibble → modern data frames (better printing, easier handling)\npurrr → functional programming with lists (map, reduce)\nstringr → string handling\nforcats → categorical (factor) variables handling\n\n\n\n\n\n\n\nNote\n\n\n\nThe pipe function (takes the result of the expression on its left and “pipes” it into the function on its right) %&gt;% makes the workflow read like a sequence of steps.\n\n\nDemonstrations\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nMy tips and tricks\n\nFor moderate-sized datasets, I recommend using tidyverse for its readability.\nMemorize the basic commands for descriptive analyses.\nCheck the unique values and summaries of each column (e.g., unique(), summary())\nCheck a lot of contingency tables (e.g., table())\nVisualize the variables as needed (e.g., ggplot())\n\n\n\ndata.table (advanced)\n \n\nDT[i, j, by]\n\n\nWhere DT is a data.table object, the i argument is used for filtering and joining, the j argument is used for summarizing and transforming, and the by argument defines the groups to which to apply these operations.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nConvert objects to data.table:\n\nsetDT() vs. as.data.table()\nsetDT(): Converts in place\nas.data.table(): Creates a new data.table object\n\nFilter rows\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nChange data type\n\nModify-in-place\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nMake new columns\n\nModify-in-place\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nSummarize by group\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPiping\n\nIt takes the result of the expression on its left and “pipes” it into the function on its right.\nAfter R 4.3.0, the native pipe supports a _ placeholder to the right-hand side of the pipe.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPoisson regression\n\nConventional Poisson regression\n\nFor count data\n\\(log(E[Y_i|X_i])=\\beta_0+\\beta_1X_i+log(T_i)\\)\nEffect measure: rate ratio\n\nModified Poisson regression\n\nFor binary data\n\\(log(E[Y_i|X_i])=\\beta_0+\\beta_1X_i\\)\nEffect measure: risk ratio\n\n\n\n\n\n\nNote\n\n\n\nRobust standard errors are recommended in both the conventional Poisson and the modified Poisson regression models.\n\n\n\n\nRegression models (advanced)\nspeedglm package: more speedy than glm\nIt directly solves the normal equations of the weighted least squares problem at each iteration (rather than relies on a QR decomposition).\nWhy does this important?\n\\(\\rightarrow\\) In G-methods, you often create many derived variables and fit many regression models across “copied” datasets.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Content",
      "Lab 2"
    ]
  },
  {
    "objectID": "Assignment1.html",
    "href": "Assignment1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Comments on the assignment 1\n\nI prefer to provide a simple framework and/or figures alongside the text.\n\nQ1: the PECO format\nQ3: subject selection flow\nQ6: DAG\n\nInformation bias\n\nMeasurement error: mismeasurment of continuous variables (sometimes, random error, not systemic error, is called “measurement error”)\nMisclassification: inaccuracy of categorical variables (sometimes, this is called “information bias”)\n\n\nDAG may help understand the bias\n\nSelection bias\n\n\n\n\n\n\n\n\n\n\n\nMisclassification (Differentiality vs. Dependence)\n\n\nDifferentiality\nNondifferential: Sensitivity and specificity are independent of another key variable\nvs. \nDifferential: Sensitivity and specificity are not independent of another key variable\n\n\nDependence\nIndependent: Misclassification of one variable does not change the probability that subjects will be misclassified on a second variable\nvs. \nDependent: The probability of being doubly misclassified is not equal to the product of the probabilities of being singly misclassified with respect to exposure and outcome. (e.g., sensitivity of exposure misclassification is correlated with sensitivity of outcome misclassification)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPresentation\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Content",
      "Assignment 1"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "Welcome!\nThis website is a collection of lab materials for the EPID8313 course (2025). The labs are designed to help you practice and apply the concepts covered in the course.\nDuring each lab session (typically held before the journal club), I will address your specific questions using the resources provided here. To allow sufficient preparation time, please submit your questions at least one day in advance. If no questions are submitted, I will review the core concepts of the lab material for about 10–15 minutes before transitioning to the journal club.\nFor the journal club, you should prepare several slides summarizing the assigned articles. Each presentation will typically take around 15 minutes per article.\n\n\nInstroctor\n\nAki Shiroshita, MD, MPH\n4th-year Epidemiology PhD student\nOriginally from Japan\nFulbright grantee\nResearch interest: Environmental epidemiology, pharmacoepidemiology\nDissertation: Traffic-related environmental exposures during early life and adverse health outcomes",
    "crumbs": [
      "Home",
      "Content",
      "Overview"
    ]
  },
  {
    "objectID": "Lab3.html",
    "href": "Lab3.html",
    "title": "Lab 3",
    "section": "",
    "text": "Lab 3 covers\n\nMissing data\n\n\nMissing mechanism\nMissing completely at random (MCAR), Missing at random (MAR), and Missing not at random (MNAR)\nThese are assumptions that cannot be directly verified using the data.\n\nExample writing of your method section\n\n\nMissing data were handled using multiple imputation by chained equations, assuming data were missing at random. The imputation model included the covariates used in the outcome analysis (XXX, YYY, and ZZZ), the treatment variable, the outcome variable, and ABC as an auxiliary variable. XXX regression models were fit to each imputed dataset, and the results from 100 imputations were combined using Rubin’s rules. … As a sensitivity analysis, we performed a complete case analysis.\n\n\n\n\n\n\n\n\n\n\n\n\nMy favoriate workflow\n\nPackage-dependent practice\n\nThe standard mice workflow often uses with() and pool().\n# 1. IMPUTE: Create 10 imputed datasets\nimp_multi &lt;- mice(support, m = 10, printFlag = FALSE, seed = 123)\n\n# It's good practice to save the imputation object\n# write_rds(imp_multi, 'imputed_data.rds')\n\n# 2. ANALYZE: Run the model on each imputed dataset\n# The 'with()' function does this automatically\nanalysis_results &lt;- with(imp_multi,\n                         glm(death ~ dzclass + age + sex + edu + income + race + diabetes + wblc,\n                             family = binomial))\n\n# 3. POOL: Combine the results using Rubin's Rules\npooled_results &lt;- pool(analysis_results)\n\nMy favorite workflow\n\nHowever, you may encounter situations where existing packages do not support your study design (e.g., performing propensity score analysis with multiple imputation).\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nMultiple imputation\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nStack\n\nConvert your multiply imputed datasets into a single dataframe where each imputed dataset is stacked on top of each other.\n\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nNest\n\n\ngroup_by(.imp) -&gt; Treat each imputed dataset separately\nnest() -&gt; Creates a list-column where each row contains one dataset (data column)\nmutate(fit = map(...)) -&gt; Iterate over the list of datasets, run the model on each one, and store the model object in a new list-column called fit.\n\n\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nRubin’s rule\n\nNow we can pool the results using the mitools package.\nsummary(mitools::MIcombine(imp_analysis$fit))\nYou can use coefs and vcovs, instead of fit.",
    "crumbs": [
      "Home",
      "Content",
      "Lab 3"
    ]
  }
]