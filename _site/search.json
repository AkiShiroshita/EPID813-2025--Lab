[
  {
    "objectID": "slide-embed.html",
    "href": "slide-embed.html",
    "title": "Embed Slides",
    "section": "",
    "text": "On this page, we show how we can embed a RevealJS Presentation inside of a Quarto Website."
  },
  {
    "objectID": "slide-embed.html#presentation",
    "href": "slide-embed.html#presentation",
    "title": "Embed Slides",
    "section": "Presentation",
    "text": "Presentation\n\n\n\n\n\n\nImportant\n\n\n\nFor quarto-webr to work within RevealJS, you must use a pre-release version of Quarto that is 1.4.502 or greater that contains an updated copy of pandoc. For more details, please see Issue #14."
  },
  {
    "objectID": "slide-embed.html#embed-code",
    "href": "slide-embed.html#embed-code",
    "title": "Embed Slides",
    "section": "Embed Code",
    "text": "Embed Code\nPlace the following code inside of the Quarto Document:\n&lt;style&gt;\n.slide-deck {\n    border: 3px solid #dee2e6;\n    width: 100%;\n    height: 475px;\n}\n&lt;/style&gt;\n\n&lt;div&gt;\n```{=html}\n&lt;iframe class=\"slide-deck\" src=\"path/to/presentation/\"&gt;&lt;/iframe&gt;\n```\n&lt;/div&gt;"
  },
  {
    "objectID": "Lab5.html",
    "href": "Lab5.html",
    "title": "Lab 5",
    "section": "",
    "text": "Lab 5 covers\n\nPropensity score analysis\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nVery simplified workflow\n\n\nEstimate the propensity score\n\n\\(Pr(Tr=1|Covariates)\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nUse the propensity score: weighting, matching, stratification, etc.\n\nInverse probability weighting\n\nAmong treated: \\(W = 1/PS\\)\nAmong untreated: \\(W = 1/(1-PS)\\)\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nBalance check\n\nLove plot, histogram, etc.\nEnsure that the weighted standardized mean difference for each covariate is less than 0.1 (or, if acceptable, less than 0.25).\n\nUnweighted samples\n\nContinuous variables: \\(d=100*\\frac{\\bar{x}_{treatment}-\\bar{x}_{control}}{\\sqrt{\\frac{S^2_{treatment}+S^2_{control}}{2}}}\\)\nBinary variables: \\(d=100*\\frac{\\hat{p}_{treatment}-\\hat{p}_{control}}{\\sqrt{\\frac{\\hat{p}_{treatment}(1-\\hat{p}_{treatment})+\\hat{p}_{control}(1-\\hat{p}_{control}}{2}}}\\)\n\nWeighted samples\n\n\\(\\bar{x}_{weight}=\\frac{\\sum w_i x_i}{\\sum w_i}\\)\n\\(s^2_{weight}=\\frac{\\sum w_i}{(\\sum w_i)^2-\\sum w_i} \\sum w_i (x_i-\\bar{x}_{weight})^2\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nRun the outcome analysis\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nWe will elaborate on this workflow in Lab 5.\n\n\n\n\n\n\nNote\n\n\n\nConsider uncertainty of propensity score estimation! \\(\\rightarrow\\) Use robust standard error or bootstrap confidence interval",
    "crumbs": [
      "Home",
      "Content",
      "Lab 5"
    ]
  },
  {
    "objectID": "Lab3.html",
    "href": "Lab3.html",
    "title": "Lab 3",
    "section": "",
    "text": "Lab 3 covers\n\nMissing data\n\n\nMissing mechanism\nMissing completely at random (MCAR), Missing at random (MAR), and Missing not at random (MNAR)\nThese are assumptions that cannot be directly verified using the data.\n\nExample writing of your method section\n\n\nMissing data were handled using multiple imputation by chained equations, assuming data were missing at random. The imputation model included the covariates used in the outcome analysis (XXX, YYY, and ZZZ), the treatment variable, the outcome variable, and ABC as an auxiliary variable. XXX regression models were fit to each imputed dataset, and the results from 100 imputations were combined using Rubin’s rules. … As a sensitivity analysis, we performed a complete case analysis.\n\n\n\n\n\n\n\n\n\n\n\n\nMy favoriate workflow\n\nPackage-dependent practice\n\nThe standard mice workflow often uses with() and pool().\n# 1. IMPUTE: Create 10 imputed datasets\nimp_multi &lt;- mice(support, m = 10, printFlag = FALSE, seed = 123)\n\n# It's good practice to save the imputation object\n# write_rds(imp_multi, 'imputed_data.rds')\n\n# 2. ANALYZE: Run the model on each imputed dataset\n# The 'with()' function does this automatically\nanalysis_results &lt;- with(imp_multi,\nglm(death ~ dzclass + age + sex + edu + income + race + diabetes + wblc,\nfamily = binomial))\n\n# 3. POOL: Combine the results using Rubin's Rules\npooled_results &lt;- pool(analysis_results)\n\nMy favorite workflow\n\nHowever, you may encounter situations where existing packages do not support your study design (e.g., performing propensity score analysis with multiple imputation).\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nMultiple imputation\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nStack\n\nConvert your multiply imputed datasets into a single dataframe where each imputed dataset is stacked on top of each other.\n\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nNest\n\n\ngroup_by(.imp) -&gt; Treat each imputed dataset separately\nnest() -&gt; Creates a list-column where each row contains one dataset (data column)\nmutate(fit = map(...)) -&gt; Iterate over the list of datasets, run the model on each one, and store the model object in a new list-column called fit.\n\n\n\n\n\n\n\n\n\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nRubin’s rule\n\nNow we can pool the results using the mitools package.\nsummary(mitools::MIcombine(imp_analysis$fit))\nYou can use coefs and vcovs, instead of fit.\n\n\nMore advanced coding\nYou can speed up your work by using data.table and speedglm.\nimp_long_dt &lt;- complete(imp_multi, action = \"long\")\nsetDT(imp_long_dt)\n\nlibrary(speedglm)\n\nimp_analysis &lt;- imp_long_dt[, {\n  # For each group, fit the logistic regression model\n  model &lt;- speedglm(death ~ dzclass + age + sex + edu + income + race + diabetes + wblc,\n                    family = binomial(), data = .SD)\n  # Return a list containing the coefficients and vcov matrix for this group\n  # These are wrapped in an outer list() to create list-columns.\n  list(coefs = list(coef(model)), vcovs = list(vcov(model)))\n}, by = .imp]\n\npooled_results &lt;- mitools::MIcombine(imp_analysis$coefs, imp_analysis$vcovs)\nsummary(pooled_results)",
    "crumbs": [
      "Home",
      "Content",
      "Lab 3"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "Welcome!\nThis website is a collection of lab materials for the EPID8313 course (2025). The labs are designed to help you practice and apply the concepts covered in the course.\nDuring each lab session (typically held before the journal club), I will address your specific questions using the resources provided here. To allow sufficient preparation time, please submit your questions at least one day in advance. If no questions are submitted, I will review the core concepts of the lab material for about 10–15 minutes before transitioning to the journal club.\nFor the journal club, you should prepare several slides summarizing the assigned articles. Each presentation will typically take around 15 minutes per article.\n\n\nInstroctor\n\nAki Shiroshita, MD, MPH\n4th-year Epidemiology PhD student\nOriginally from Japan\nFulbright grantee\nResearch interest: Environmental epidemiology, pharmacoepidemiology\nDissertation: Traffic-related environmental exposures during early life and adverse health outcomes",
    "crumbs": [
      "Home",
      "Content",
      "Overview"
    ]
  },
  {
    "objectID": "Assignment1.html",
    "href": "Assignment1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "Comments on the assignment 1\n\nI prefer to provide a simple framework and/or figures alongside the text.\n\nQ1: the PECO format\nQ3: subject selection flow\nQ6: DAG\n\nInformation bias\n\nMeasurement error: mismeasurment of continuous variables (sometimes, random error, not systemic error, is called “measurement error”)\nMisclassification: inaccuracy of categorical variables (sometimes, this is called “information bias”)\n\n\nDAG may help understand the bias\n\nSelection bias\n\n\n\n\n\n\n\n\n\n\n\nMisclassification (Differentiality vs. Dependence)\n\n\nDifferentiality\nNondifferential: Sensitivity and specificity are independent of another key variable\nvs. \nDifferential: Sensitivity and specificity are not independent of another key variable\n\n\nDependence\nIndependent: Misclassification of one variable does not change the probability that subjects will be misclassified on a second variable\nvs. \nDependent: The probability of being doubly misclassified is not equal to the product of the probabilities of being singly misclassified with respect to exposure and outcome. (e.g., sensitivity of exposure misclassification is correlated with sensitivity of outcome misclassification)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPresentation\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Content",
      "Assignment 1"
    ]
  },
  {
    "objectID": "Assignment2.html",
    "href": "Assignment2.html",
    "title": "Assignment 2",
    "section": "",
    "text": "Comments on the assignment 2\n\nSignificant Digits (or significant figures)\n\nSignificant digits and decimal points are two different concepts. We usually use significant digits in scientific papers, although we prioritize adhere to the guidelines provided by the journal to which you are submitting.\nEnsure that significant digits are consistent and meaningful.\nFor example, someone said that decimal places in percentages may not provide meaningful information and rounding to a whole number may be better (e.g., \\(12.2\\)% \\(\\rightarrow\\) \\(12%\\))\nHow many significant digits are in the following numbers?\n\n\\(287\\)\n\nNon-zero digits are always significant.\n\n\\(50.03\\)\n\nZeros between non-zero digits are significant.\n\n\\(0.0045\\)\n\nLeading zeros (zeros at the beginning of a number) are never significant.\n\n\\(3.20 \\times 10^3\\)\n\nTrailing zeros (zeros at the end of a number) are significant only if the number contains a decimal point.\n\n\\(1,200.0\\)\n\n\n\n\n\n\n\nNote\n\n\n\nWhile tableone is excellent, gtsummary generally offers more flexible control for formatting by significant digits.\n\n\n\nsuppressPackageStartupMessages(library(tidyverse))\nlibrary(gtsummary)\nprostate &lt;- read.csv('https://raw.githubusercontent.com/AkiShiroshita/EPID813-2025--Lab/refs/heads/main/data/prostate.csv')\n\n# custom function\nfmt_sigfig &lt;- function(x, sigfig = 3) {\n  signif(x, sigfig)\n}\n\n# tbl_summary() applies whatever function you provide to format the numbers.\nprostate %&gt;%\n  dplyr::select(age, sbp, hg, ap) %&gt;%\n  gtsummary::tbl_summary(\n    statistic = all_continuous() ~ \"{mean} ({sd})\",\n    digits = all_continuous() ~ function(x) fmt_sigfig(x, sigfig = 3)\n  )\n\n\n\n\n\n\n\nCharacteristic\nN = 5021\n\n\n\n\nage\n71.5 (7.08)\n\n\n    Unknown\n1\n\n\nsbp\n14.4 (2.42)\n\n\nhg\n13.4 (1.95)\n\n\nap\n12.2 (62.2)\n\n\n\n1 Mean (SD)\n\n\n\n\n\n\n\n\n\nround()\n\nR uses round to even (also known as “bankers’ rounding”) to handle ties. This means that if the number to be rounded is exactly halfway between two possible rounded values, it rounds to the nearest even number.\nThe underlying behavior of tableone and gtsummaryis the same.\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n\nPresentation\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Content",
      "Assignment 2"
    ]
  },
  {
    "objectID": "Lab2.html",
    "href": "Lab2.html",
    "title": "Lab 2",
    "section": "",
    "text": "Lab 2 covers\n\ndata wrangling\nregression models.\n\n\nData wrangling\n\nbase R\ntidyverse: clean and readable\ndata.table: Optimized for speed and memory efficiency\n\n\n\n\n\n\n\nNote\n\n\n\nAs I use very large-scale environmental data, I am switching from tidyverse to data.table.\n\n\n\n\ntidyverse\nA philosophy created by Hadley Wickham\n\ndplyr → data manipulation (filter, mutate, group, summarize)\nggplot2 → data visualization\ntidyr → data tidying (reshaping, pivoting, separating)\nreadr → data import (CSV, TSV, etc.)\ntibble → modern data frames (better printing, easier handling)\npurrr → functional programming with lists (map, reduce)\nstringr → string handling\nforcats → categorical (factor) variables handling\n\n\n\n\n\n\n\nNote\n\n\n\nThe pipe function (takes the result of the expression on its left and “pipes” it into the function on its right) %&gt;% makes the workflow read like a sequence of steps.\n\n\nDemonstrations\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nMy tips and tricks\n\nFor moderate-sized datasets, I recommend using tidyverse for its readability.\nMemorize the basic commands for descriptive analyses.\nCheck the unique values and summaries of each column (e.g., unique(), summary())\nCheck a lot of contingency tables (e.g., table())\nVisualize the variables as needed (e.g., ggplot())\n\n\n\ndata.table (advanced)\n \n\nDT[i, j, by]\n\n\nWhere DT is a data.table object, the i argument is used for filtering and joining, the j argument is used for summarizing and transforming, and the by argument defines the groups to which to apply these operations.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nConvert objects to data.table:\n\nsetDT() vs. as.data.table()\nsetDT(): Converts in place\nas.data.table(): Creates a new data.table object\n\nFilter rows\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nChange data type\n\nModify-in-place\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nMake new columns\n\nModify-in-place\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nSummarize by group\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPiping\n\nIt takes the result of the expression on its left and “pipes” it into the function on its right.\nAfter R 4.3.0, the native pipe supports a _ placeholder to the right-hand side of the pipe.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nPoisson regression\n\nConventional Poisson regression\n\nFor count data\n\\(log(E[Y_i|X_i])=\\beta_0+\\beta_1X_i+log(T_i)\\)\nEffect measure: rate ratio\n\nModified Poisson regression\n\nFor binary data\n\\(log(E[Y_i|X_i])=\\beta_0+\\beta_1X_i\\)\nEffect measure: risk ratio\n\n\n\n\n\n\nNote\n\n\n\nRobust standard errors are recommended in both the conventional Poisson and the modified Poisson regression models.\n\n\n\n\nRegression models (advanced)\nspeedglm package: more speedy than glm\nIt directly solves the normal equations of the weighted least squares problem at each iteration (rather than relies on a QR decomposition).\nWhy does this important?\n\\(\\rightarrow\\) In G-methods, you often create many derived variables and fit many regression models across “copied” datasets.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.",
    "crumbs": [
      "Home",
      "Content",
      "Lab 2"
    ]
  },
  {
    "objectID": "Lab4.html",
    "href": "Lab4.html",
    "title": "Lab 4",
    "section": "",
    "text": "Lab 4 covers\n\nPower and sample size calculation\n\nIn many cases, we want to perform power calculations for multivariable regression models.\n\n\n\n\n\n\nNote\n\n\n\nPower = probability of rejecting the null hypothesis if a specific alternative is true\n\n\n\nBrief overview of software\n\nR packages: pwr, pwrss, etc.\nSTATA\nSAS Proc Power\nPS: Power and Sample Size Calculation (Vanderbilt University, free): https://cqsclinical.app.vumc.org/ps/\nG*Power (free, less intuitive): https://www.psychologie.hhu.de/arbeitsgruppen/allgemeine-psychologie-und-arbeitspsychologie/gpower\nPASS (NCSS, commercial, most flexible): https://www.ncss.com/software/pass/\nEPI Info (CDC, free): https://www.cdc.gov/epiinfo/index.html\nOptimal Design (free, program for multilevel modeling): https://www.wtgrantfoundation.org/resources/optimal-design\nFor conducting complex statistical analyses (e.g., propensity score analysis), I recommend using Monte Carlo simulations.\n\n\n\nR pwrss package\nTutorial: https://rpubs.com/metinbulus/pwrss\nPower and sample size calculation based on the Wald test.\nScenario: You are planning a study where the outcome is binary and will be analyzed with logistic regression.\nWhat you need is\n\np0: probability of the outcome when the predictor is at reference level (e.g., control group).\np1: probability of the outcome when the predictor is at the exposure level (e.g., treatment group).\nr2.other.x: A squared multiple correlation between an exposure and other covariates\n\nHigher values indicate more correlation, which will increase the required sample size.\nYou can calculate r2.other.x by fitting a linear regression model where your main predictor of interest is treated as the outcome and all other covariates are the predictors.\nfit &lt;- lm(exposure ~ cov1+cov2, data = data)\n# Extract the R-squared value\nsummary_model &lt;- summary(fit)\nr2_estimate &lt;- summary_model$r.squared\n\ndist: distribution of the predictor (e.g., normal, bernoulli, etc.)\nn: total sample size\nalpha = 0.05: significance level\n\n\npwrss::pwrss.z.logreg(\n  p0 = 0.11,\n  p1 = 0.10,\n  r2.other.x = 0.10,\n  dist = list(dist = \"normal\", mean = 10, sd = 2),\n  n = 8000,\n  alpha = 0.05\n)\n\n+--------------------------------------------------+\n|                POWER CALCULATION                 |\n+--------------------------------------------------+\n\nLogistic Regression Coefficient (Wald's Z-Test)\n\n  Method          : Demidenko (Variance Corrected)\n  Predictor Dist. : Normal\n\n---------------------------------------------------\nHypotheses\n---------------------------------------------------\n  H0 (Null Claim) : Odds Ratio = 1\n  H1 (Alt. Claim) : Odds Ratio != 1\n\n---------------------------------------------------\nResults\n---------------------------------------------------\n  Sample Size          = 8000\n  Type 1 Error (alpha) = 0.050\n  Type 2 Error (beta)  = 0.050\n  Statistical Power    = 0.95  &lt;&lt;\n\n\n\nExample writing of your method section\n\n\nFor our primary analysis, a sample size of 8,000 provides approximately 81% power to detect an odds ratio of 0.90 for PM2.5, assuming a baseline outcome prevalence of 11% and a normally distributed PM2.5 exposure (mean = 10, SD = 2). This calculation was performed using a two-sided z-test at a significance level of 0.05 and accounts for potential confounding by assuming that other covariates explain 10% of the variance in the exposure (i.e., a squared multiple correlation of 0.1 between the primary exposure and other covariates)\n\n\n\n\n\n\n\nNote\n\n\n\n\nOdds for the reference group: \\(0.11/(1−0.11)=0.1236\\)\nOdds for the comparison group: \\(0.10/(1−0.10)=0.1111\\)\nOdds Ratio \\(= 0.1111/0.1236 \\approx 0.90\\)",
    "crumbs": [
      "Home",
      "Content",
      "Lab 4"
    ]
  },
  {
    "objectID": "Midterm_review.html",
    "href": "Midterm_review.html",
    "title": "Midterm review",
    "section": "",
    "text": "Bias\n\nSuppose the true population:\n\n\n\n\nCases\nControls\nTotal\n\n\n\n\nExposed\n30\n70\n100\n\n\nUnexposed\n20\n80\n100\n\n\n\nObserved population:\n\n\n\n\nCases\nControls\nTotal\n\n\n\n\nExposed\n30\n20\n50\n\n\nUnexposed\n20\n80\n100\n\n\n\n\n\n\n\n\n\nQ1: What is this bias called? If the true population is unknown but the selection probabilities are known, how can this bias be corrected?\n\n\n\n\n\nA: selection bias.\n\n\n\nSelection probabilities\nCases\nControls\n\n\n\n\n\nExposed\n\\(S_{A,1}\\)\n\\(S_{B,1}\\)\n\n\n\nUnexposed\n\\(S_{A,0}\\)\n\\(S_{B,0}\\)\n\n\n\n\nTRUE \\(OR = \\hat{OR}/\\frac{S_{A,1}S_{B,0}}{S_{A,0}S_{B,1}}\\)\nwhere selection odds ratio = \\(\\frac{S_{A,1}S_{B,0}}{S_{A,0}S_{B,1}}\\)\nTo cause selection bias, selection should depend jointly on the exposure and outcome.\nThe following scenarios do not cause bias:\n\nIf selection depends only on exposure\nIf selection depends only on outcome\nIf selection depends proportionally on both (independently) \\(\\rightarrow P(selected|exposure,outcome)=f(exposure) \\times g(outcome)\\)\n\n\n\n\nSuppose the true population:\n\n\n\nTrue Smoking\nLung Cancer\nNo Lung Cancer\nTotal\n\n\n\n\nSmoker\n40\n60\n100\n\n\nNon-Smoker\n10\n90\n100\n\n\n\n\n\n\n\n\n\nQ2: If 20% of smokers are misclassified as non-smokers, what is the observed odds ratio between smoking and lung cancer? What is this bias called?\n\n\n\n\n\n\n\n\nObserved Smoking\nLung Cancer\nNo Lung Cancer\nTotal\n\n\n\n\nSmoker\n40-40*0.2=32\n60-60*0.2=48\n80\n\n\nNon-Smoker\n10+40*0.2=18\n90+60*0.2=102\n120\n\n\n\nA: The observed odds ratio is (32*102)/(48*18)=3.78. This bias is called non-differential misclassification of a binary exposure.\n\n\n\n\n\n\n\n\n\nQ3: Non-differential misclassification always biased the estimate toward the null. Is that correct?\n\n\n\n\n\nA: FALSE.\nExceptions:\n\nIf the exposure has more than two categories\nIf the exposure is continuous\nOutcome misclassification\n\netc. (Please see the Journal Club)\n\n\n\n\n\n\n\n\n\nQ4: In a prospective study comparing myocardial infarction mortality between office workers and longshoremen, individuals who self-select into longshoremen are generally fitter, which leads to lower myocardial infarction rates. What type of bias does this introduce?\n\n\n\n\n\nA: confounding bias from a traditional epidemiological view (not selection bias)\nThe difference is that, in confounding, individuals self-select into exposure groups, whereas in selection bias, the researcher’s process of selecting participants into the study creates the bias.\nTraditional view is cohort studies don’t have selection bias at entry even if subjects self-select.\nCohort studies/RCTs can have selection bias at end through differential loss to follow-up.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMissing data\n\n\n\n\n\n\n\nQ5: One important difference between single imputation and multiple imputation is that the latter can appropriately account for the uncertainty of the imputed values. Another important difference is that the outcome variable should be included in the multiple imputation model. Is that correct?\n\n\n\n\n\nA: TRUE.\nIt is recommended to include the outcome variable in the imputation model, even if the outcome is not missing, because omitting it can bias regression coefficients. However, imputing outcome is a debatable topic.\n\n\n\n\nModel building\n\n\n\n\n\n\n\nQ6: If you develop a prediction model, what model performance metrics would you report?\n\n\n\n\n\nA:\n\nCalibration: Measures how closely the predicted probabilities agree with the observed outcomes (e.g., calibration plot, Hosmer-Lemeshow test).\nDiscrimination: Measures how well the model distinguishes between individuals with and without the outcome (e.g., AUC/ROC, C-statistic)\n\nWe often use optimism-corrected performance metrics through internal validation (e.g., bootstrapping) to account for overfitting.\nYou may report other metrics as well, such as overall performance (e.g., Brier score) and reclassification metrics (e.g., NRI, IDI)\n\n\n\n\nMatching\n\n\n\n\n\n\n\nQ7: Where do you select cases and controls in a case-control study? Are there any caveats regarding their sources?\n\n\n\n\n\nA:\n\nDetermine cases and and identify a source from which to draw their cases.\nIdentify controls from the same source population.The fundamental principle is that controls should be representative of the population from which the cases arose. In other words, they should be selected independently of exposures.\n\nNaturally occurring pairs, such as twins, can violate this principle in matched case-control studies because their inherent relationship introduces correlation beyond what matching accounts for, potentially biasing the results.\n\n\n\n\n\n\n\n\n\nQ8: In an individual (pair) case-control study, if you match on age and sex, you do not need to adjust for them in the conditional logistic regression model, even if they are potential confounders. Is that correct?\n\n\n\n\n\nA: False.\nMatching is for efficiency gain, not for controlling for confounders. Therefore, conditional logistic regression models should include all potential confounders, even if they are matching factors. (If we use frequency matching, we may use unconditional logistic regression with adjustment for all potential confounders, including matching factors)\nIn addition, please note that association of age and sex with the outcome as well as interactions between the exposure and these matching factors cannot be estimated in the conditional logistic regression model.\n\n\n\n\n\n\n\n\n\nQ9: When the outcome is rare, what does the odds ratio estimated from the following matched design represent?: 1. case-cohort sampling, 2. risk-set sampling, and 3. survivor sampling\n\n\n\n\n\n\nCase-cohort sampling: Risk ratio\nRisk-set sampling (density-based sampling): Incidence rate ratio\nSurvivor sampling: Odds ratio\n\nThe derivations are shown in the document I shared earlier.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQ10: What is the difference between a case-crossover design and a self-controlled case series?\n\n\n\n\n\nA: Both are “case-only” designs that use individuals as their own controls to study the effects of transient exposures on acute events.\nA case-crossover study is outcome-anchored design, while a self-controlled case series is exposure-anchored design.\nIn a case-crossover study, researchers focus on a specific event (e.g., heart attack) and look back at the exposure history immediately before the event (the “case” period). They then compare this to the exposure history during an earlier period (the “control” period) for the same individual.\nA self-controlled case series, on the other hand, looks at the entire observation period for an individual and divides it into “at-risk” periods (times after a specific exposure) and “control” periods (all other time). It then compares the rate of events during the at-risk periods to the rate of events during the control periods.\n\n\n\n\n\n\n\n\n\n\n\n\n\nPropensity score analysis\n\n\n\n\n\n\n\nQ11: Propensity score is the probability of receiving treatment given covariates. Therefore, we should include predictors of treatment in the propensity score model. Is that correct?\n\n\n\n\n\nA: False.\nThe propensity score model should include confounders and predictors of the outcome, but not instrumental variables.\n\n\n\nSuppose 30% of the patients received the treatment, and the following table summarizes their potential outcomes.\n\n\n\nGroup\n\\(E(Y^1)\\)\n\\(E(Y^0)\\)\n\n\n\n\nTreatment\n100\n60\n\n\nNo treatment\n80\n50\n\n\n\n\n\n\n\n\n\nQ12: Calculate the following treatment effects: ATE, ATT, and ATU.\n\n\n\n\n\nA:\nATT: \\(100-60=40\\)\nATU: \\(80-50=30\\)\nATE: \\(0.3*(100-60)+0.7*(80-50)=12+21=33\\)\n\n\n\nBased on the following tables,\n\\(C=0\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n10\n50\n\n\nNo event\n790\n3150\n\n\nTotal\n800\n3200\n\n\n\n\\(C=1\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n200\n250\n\n\nNo event\n800\n750\n\n\nTotal\n1000\n1000\n\n\n\n\n\n\n\n\n\nQ13: Is C a confounder or effect modifier? Hand-calculate adjusted risk ratio using propensity score matching (1:1 matching) and inverse probability weighting.\n\n\n\n\n\nA: C is a confounder because it is associated with both the treatment and the outcome.\n\nWithin each stratum of C, the treatment effect (RR = 0.8) is the same (if C is the effect modifier, RR is not the same across strata).\nThe crude/overall effect (RR = 1.63) is very different from the stratum-specific effects.\n\nPropensity score calculation\n\\(Pr(Tr=1|C=0)=800/(800+3200)=0.2\\)\n\\(Pr(Tr=1|C=1)=1000/(1000+1000)=0.2\\)\n\nPropensity score matching (1:1 matching)\n\nIt is equivalent to taking a random sample of the unexposed group that is equal in size to the exposed group (the risk of the outcome will remain the same as in the original unexposed group), because each exposed individual is matched to one unexposed individual with a similar propensity score (the matched unexposed group is a subset of the original unexposed group, chosen to resemble the exposed group in terms of covariates)\n\\(C=0\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n10\n800*50/3200=12.5\n\n\nNo event\n790\n800*(3200-50)/3200=787.5\n\n\nTotal\n800\n800\n\n\n\n\\(C=1\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n200\n250\n\n\nNo event\n800\n750\n\n\nTotal\n1000\n1000\n\n\n\n\\(Overall\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n210\n262.5\n\n\nNo event\n1590\n1537.5\n\n\nTotal\n1800\n1800\n\n\n\nRR: 0.8\n\nPropensity score weighting\n\n\\(C=0\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n10*(1/0.2)=50\n50*(1/0.8)=62.5\n\n\nNo event\n790*(1/0.2)=3950\n3150*(1/0.8)=3937.5\n\n\n\nTreatment group weight = \\(1/PS=1/0.2=5\\)\nNon-treatment group weight = \\(1/PS=1/(1-0.2)=1.25\\)\n\\(C=1\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n200*(1/0.5)=400\n250*(1/0.5)=500\n\n\nNo event\n800*(1/0.5)=1600\n750*(1/0.5)=1500\n\n\n\nTreatment group weight = \\(1/PS=1/0.5=2\\)\nNon-treatment group weight = \\(1/PS=1/(1-0.5)=2\\)\n\\(Overall\\)\n\n\n\n\nTreatment\nNo treatment\n\n\n\n\nEvent\n450\n562.5\n\n\nNo event\n5550\n5437.5\n\n\nTotal\n6000\n6000\n\n\n\nRR: 0.8",
    "crumbs": [
      "Home",
      "Content",
      "Midterm review"
    ]
  }
]